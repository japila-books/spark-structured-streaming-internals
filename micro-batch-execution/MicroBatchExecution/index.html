<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Demystifying inner-workings of Spark Structured Streaming"><meta name=author content="Jacek Laskowski"><link href=https://jaceklaskowski.github.io/spark-structured-streaming-book/micro-batch-execution/MicroBatchExecution/ rel=canonical><link rel="shortcut icon" href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.1.2, mkdocs-material-6.2.8+insiders-1.17.0"><title>MicroBatchExecution - The Internals of Spark Structured Streaming</title><link rel=stylesheet href=../../assets/stylesheets/main.10cb3b3f.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.697e47cb.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>:root{--md-text-font-family:"Roboto",;--md-code-font-family:"Roboto Mono",}</style><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-151208281-3","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview",document.location.pathname)})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <script>var palette=JSON.parse(localStorage.getItem("__palette"));if(null!==palette&&"object"==typeof palette.color)for(var key in palette.color)document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#microbatchexecution class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=https://jaceklaskowski.github.io/spark-structured-streaming-book/ title="The Internals of Spark Structured Streaming" class="md-header__button md-logo" aria-label="The Internals of Spark Structured Streaming"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 2l-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> The Internals of Spark Structured Streaming </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> MicroBatchExecution </span> </div> </div> </div> <div class=md-header__options> <button class="md-header__button md-icon" title="Switch to light mode" aria-label="Switch to light mode" data-md-option=palette data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo data-md-state=hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 015 5 5 5 0 01-5 5 5 5 0 01-5-5 5 5 0 015-5m0 2a3 3 0 00-3 3 3 3 0 003 3 3 3 0 003-3 3 3 0 00-3-3m0-7l2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 005.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10l1.76-3.77a7.131 7.131 0 002.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 00-2.38-4.15l4.15.36m-.01 10l-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22z"/></svg> </button> <button class="md-header__button md-icon" title="Switch to dark mode" aria-label="Switch to dark mode" data-md-option=palette data-md-color-scheme=slate data-md-color-primary=blue data-md-color-accent=blue data-md-state=hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17.75 4.09l-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91l-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 008.02 2.89m-1.64 2.02a12.08 12.08 0 01-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31z"/></svg> </button> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" aria-label=Clear data-md-component=search-reset tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/jaceklaskowski/spark-structured-streaming-book/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> spark-structured-streaming-internals </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../spark-structured-streaming/ class="md-tabs__link md-tabs__link--active"> Internals </a> </li> <li class=md-tabs__item> <a href=../../operators/ class=md-tabs__link> Streaming Operators </a> </li> <li class=md-tabs__item> <a href=../../datasources/ class=md-tabs__link> Data Sources </a> </li> <li class=md-tabs__item> <a href=../../monitoring/StreamingQueryListener/ class=md-tabs__link> Monitoring </a> </li> <li class=md-tabs__item> <a href=../../webui/ class=md-tabs__link> Web UI </a> </li> <li class=md-tabs__item> <a href=../../demo/ class=md-tabs__link> Demos </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=https://jaceklaskowski.github.io/spark-structured-streaming-book/ title="The Internals of Spark Structured Streaming" class="md-nav__button md-logo" aria-label="The Internals of Spark Structured Streaming"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 2l-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5z"/></svg> </a> The Internals of Spark Structured Streaming </label> <div class=md-nav__source> <a href=https://github.com/jaceklaskowski/spark-structured-streaming-book/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> spark-structured-streaming-internals </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1 type=checkbox id=nav-1> <div class="md-nav__link md-nav__link--container "> <a href=../..>Home</a> <label for=nav-1> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=Home data-md-level=1> <label class=md-nav__title for=nav-1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2 type=checkbox id=nav-2 checked> <label class=md-nav__link for=nav-2> Internals <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Internals data-md-level=1> <label class=md-nav__title for=nav-2> <span class="md-nav__icon md-icon"></span> Internals </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../spark-structured-streaming/ class=md-nav__link> Spark Structured Streaming and Streaming Queries </a> </li> <li class=md-nav__item> <a href=../../StreamingQuery/ class=md-nav__link> StreamingQuery </a> </li> <li class=md-nav__item> <a href=../../configuration-properties/ class=md-nav__link> Configuration Properties </a> </li> <li class=md-nav__item> <a href=../../spark-structured-streaming-batch-processing-time/ class=md-nav__link> Batch Processing Time </a> </li> <li class=md-nav__item> <a href=../../spark-structured-streaming-internals/ class=md-nav__link> Internals of Streaming Queries </a> </li> <li class=md-nav__item> <a href=../../DataSource/ class=md-nav__link> DataSource </a> </li> <li class=md-nav__item> <a href=../../SparkDataStream/ class=md-nav__link> SparkDataStream </a> </li> <li class=md-nav__item> <a href=../../SupportsAdmissionControl/ class=md-nav__link> SupportsAdmissionControl </a> </li> <li class=md-nav__item> <a href=../../MicroBatchStream/ class=md-nav__link> MicroBatchStream </a> </li> <li class=md-nav__item> <a href=../../ContinuousStream/ class=md-nav__link> ContinuousStream </a> </li> <li class=md-nav__item> <a href=../../Trigger/ class=md-nav__link> Trigger </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-12 type=checkbox id=nav-2-12> <label class=md-nav__link for=nav-2-12> Streaming Join <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Streaming Join" data-md-level=2> <label class=md-nav__title for=nav-2-12> <span class="md-nav__icon md-icon"></span> Streaming Join </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../spark-sql-streaming-join/ class=md-nav__link> Streaming Join </a> </li> <li class=md-nav__item> <a href=../../StateStoreAwareZipPartitionsRDD/ class=md-nav__link> StateStoreAwareZipPartitionsRDD </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-12-3 type=checkbox id=nav-2-12-3> <label class=md-nav__link for=nav-2-12-3> SymmetricHashJoinStateManager <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=SymmetricHashJoinStateManager data-md-level=3> <label class=md-nav__title for=nav-2-12-3> <span class="md-nav__icon md-icon"></span> SymmetricHashJoinStateManager </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../SymmetricHashJoinStateManager/ class=md-nav__link> SymmetricHashJoinStateManager </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-StateStoreHandler/ class=md-nav__link> StateStoreHandler </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-KeyToNumValuesStore/ class=md-nav__link> KeyToNumValuesStore </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-KeyWithIndexToValueStore/ class=md-nav__link> KeyWithIndexToValueStore </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../OneSideHashJoiner/ class=md-nav__link> OneSideHashJoiner </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-JoinStateWatermarkPredicates/ class=md-nav__link> JoinStateWatermarkPredicates </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-JoinStateWatermarkPredicate/ class=md-nav__link> JoinStateWatermarkPredicate </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-12-7 type=checkbox id=nav-2-12-7> <label class=md-nav__link for=nav-2-12-7> StateStoreAwareZipPartitionsHelper <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StateStoreAwareZipPartitionsHelper data-md-level=3> <label class=md-nav__title for=nav-2-12-7> <span class="md-nav__icon md-icon"></span> StateStoreAwareZipPartitionsHelper </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../spark-sql-streaming-StateStoreAwareZipPartitionsHelper/ class=md-nav__link> StateStoreAwareZipPartitionsHelper </a> </li> <li class=md-nav__item> <a href=../../StreamingSymmetricHashJoinHelper/ class=md-nav__link> StreamingSymmetricHashJoinHelper </a> </li> <li class=md-nav__item> <a href=../../StreamingJoinHelper/ class=md-nav__link> StreamingJoinHelper </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-13 type=checkbox id=nav-2-13> <label class=md-nav__link for=nav-2-13> Streaming Aggregation <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Streaming Aggregation" data-md-level=2> <label class=md-nav__title for=nav-2-13> <span class="md-nav__icon md-icon"></span> Streaming Aggregation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../streaming-aggregation/ class=md-nav__link> Streaming Aggregation </a> </li> <li class=md-nav__item> <a href=../../StateStoreRDD/ class=md-nav__link> StateStoreRDD </a> </li> <li class=md-nav__item> <a href=../../StateStoreOps/ class=md-nav__link> StateStoreOps </a> </li> <li class=md-nav__item> <a href=../../StreamingAggregationStateManager/ class=md-nav__link> StreamingAggregationStateManager </a> </li> <li class=md-nav__item> <a href=../../StreamingAggregationStateManagerBaseImpl/ class=md-nav__link> StreamingAggregationStateManagerBaseImpl </a> </li> <li class=md-nav__item> <a href=../../StreamingAggregationStateManagerImplV1/ class=md-nav__link> StreamingAggregationStateManagerImplV1 </a> </li> <li class=md-nav__item> <a href=../../StreamingAggregationStateManagerImplV2/ class=md-nav__link> StreamingAggregationStateManagerImplV2 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-14 type=checkbox id=nav-2-14> <label class=md-nav__link for=nav-2-14> Stateful Stream Processing <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Stateful Stream Processing" data-md-level=2> <label class=md-nav__title for=nav-2-14> <span class="md-nav__icon md-icon"></span> Stateful Stream Processing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../spark-sql-streaming-stateful-stream-processing/ class=md-nav__link> Stateful Stream Processing </a> </li> <li class=md-nav__item> <a href=../../streaming-watermark/ class=md-nav__link> Streaming Watermark </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-deduplication/ class=md-nav__link> Streaming Deduplication </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-limit/ class=md-nav__link> Streaming Limit </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-14-5 type=checkbox id=nav-2-14-5> <label class=md-nav__link for=nav-2-14-5> StateStore <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StateStore data-md-level=3> <label class=md-nav__title for=nav-2-14-5> <span class="md-nav__icon md-icon"></span> StateStore </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../StateStore/ class=md-nav__link> StateStore </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-StateStoreId/ class=md-nav__link> StateStoreId </a> </li> <li class=md-nav__item> <a href=../../HDFSBackedStateStore/ class=md-nav__link> HDFSBackedStateStore </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-14-6 type=checkbox id=nav-2-14-6> <label class=md-nav__link for=nav-2-14-6> StateStoreProvider <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StateStoreProvider data-md-level=3> <label class=md-nav__title for=nav-2-14-6> <span class="md-nav__icon md-icon"></span> StateStoreProvider </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../spark-sql-streaming-StateStoreProvider/ class=md-nav__link> StateStoreProvider </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-StateStoreProviderId/ class=md-nav__link> StateStoreProviderId </a> </li> <li class=md-nav__item> <a href=../../HDFSBackedStateStoreProvider/ class=md-nav__link> HDFSBackedStateStoreProvider </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-14-7 type=checkbox id=nav-2-14-7> <label class=md-nav__link for=nav-2-14-7> StateStoreCoordinator <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StateStoreCoordinator data-md-level=3> <label class=md-nav__title for=nav-2-14-7> <span class="md-nav__icon md-icon"></span> StateStoreCoordinator </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../StateStoreCoordinator/ class=md-nav__link> StateStoreCoordinator </a> </li> <li class=md-nav__item> <a href=../../StateStoreCoordinatorRef/ class=md-nav__link> StateStoreCoordinatorRef </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../WatermarkSupport/ class=md-nav__link> WatermarkSupport </a> </li> <li class=md-nav__item> <a href=../../StatefulOperatorStateInfo/ class=md-nav__link> StatefulOperatorStateInfo </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-StateStoreMetrics/ class=md-nav__link> StateStoreMetrics </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-StateStoreCustomMetric/ class=md-nav__link> StateStoreCustomMetric </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-StateStoreUpdater/ class=md-nav__link> StateStoreUpdater </a> </li> <li class=md-nav__item> <a href=../../EventTimeStatsAccum/ class=md-nav__link> EventTimeStatsAccum </a> </li> <li class=md-nav__item> <a href=../../EventTimeStats/ class=md-nav__link> EventTimeStats </a> </li> <li class=md-nav__item> <a href=../../StateStoreConf/ class=md-nav__link> StateStoreConf </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-15 type=checkbox id=nav-2-15> <label class=md-nav__link for=nav-2-15> Arbitrary Stateful Streaming Aggregation <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Arbitrary Stateful Streaming Aggregation" data-md-level=2> <label class=md-nav__title for=nav-2-15> <span class="md-nav__icon md-icon"></span> Arbitrary Stateful Streaming Aggregation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../arbitrary-stateful-streaming-aggregation/ class=md-nav__link> Arbitrary Stateful Streaming Aggregation </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-15-2 type=checkbox id=nav-2-15-2> <label class=md-nav__link for=nav-2-15-2> KeyValueGroupedDataset <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=KeyValueGroupedDataset data-md-level=3> <label class=md-nav__title for=nav-2-15-2> <span class="md-nav__icon md-icon"></span> KeyValueGroupedDataset </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../KeyValueGroupedDataset/ class=md-nav__link> KeyValueGroupedDataset </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-KeyValueGroupedDataset-mapGroupsWithState/ class=md-nav__link> mapGroupsWithState Operator </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-KeyValueGroupedDataset-flatMapGroupsWithState/ class=md-nav__link> flatMapGroupsWithState Operator </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-15-3 type=checkbox id=nav-2-15-3> <label class=md-nav__link for=nav-2-15-3> GroupState <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=GroupState data-md-level=3> <label class=md-nav__title for=nav-2-15-3> <span class="md-nav__icon md-icon"></span> GroupState </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../GroupState/ class=md-nav__link> GroupState </a> </li> <li class=md-nav__item> <a href=../../GroupStateImpl/ class=md-nav__link> GroupStateImpl </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-GroupStateTimeout/ class=md-nav__link> GroupStateTimeout </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-15-5 type=checkbox id=nav-2-15-5> <label class=md-nav__link for=nav-2-15-5> StateManager <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StateManager data-md-level=3> <label class=md-nav__title for=nav-2-15-5> <span class="md-nav__icon md-icon"></span> StateManager </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../spark-sql-streaming-StateManager/ class=md-nav__link> StateManager </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-StateManagerImplV2/ class=md-nav__link> StateManagerImplV2 </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-StateManagerImplBase/ class=md-nav__link> StateManagerImplBase </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-StateManagerImplV1/ class=md-nav__link> StateManagerImplV1 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-FlatMapGroupsWithStateExecHelper/ class=md-nav__link> FlatMapGroupsWithStateExecHelper Helper Class </a> </li> <li class=md-nav__item> <a href=../../InputProcessor/ class=md-nav__link> InputProcessor </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../StreamingQueryManager/ class=md-nav__link> StreamingQueryManager </a> </li> <li class=md-nav__item> <a href=../../StreamingQueryListenerBus/ class=md-nav__link> StreamingQueryListenerBus </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-18 type=checkbox id=nav-2-18> <label class=md-nav__link for=nav-2-18> Developer-Facing APIs <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Developer-Facing APIs" data-md-level=2> <label class=md-nav__title for=nav-2-18> <span class="md-nav__icon md-icon"></span> Developer-Facing APIs </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../DataStreamReader/ class=md-nav__link> DataStreamReader </a> </li> <li class=md-nav__item> <a href=../../DataStreamWriter/ class=md-nav__link> DataStreamWriter </a> </li> <li class=md-nav__item> <a href=../../OutputMode/ class=md-nav__link> OutputMode </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-window/ class=md-nav__link> window Function </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-19 type=checkbox id=nav-2-19> <label class=md-nav__link for=nav-2-19> Query Execution <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Query Execution" data-md-level=2> <label class=md-nav__title for=nav-2-19> <span class="md-nav__icon md-icon"></span> Query Execution </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../StreamExecution/ class=md-nav__link> StreamExecution </a> </li> <li class=md-nav__item> <a href=../../IncrementalExecution/ class=md-nav__link> IncrementalExecution </a> </li> <li class=md-nav__item> <a href=../../TriggerExecutor/ class=md-nav__link> TriggerExecutor </a> </li> <li class=md-nav__item> <a href=../../StreamingQueryWrapper/ class=md-nav__link> StreamingQueryWrapper </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../StreamMetadata/ class=md-nav__link> StreamMetadata </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-21 type=checkbox id=nav-2-21> <label class=md-nav__link for=nav-2-21> Logical Operators <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Logical Operators" data-md-level=2> <label class=md-nav__title for=nav-2-21> <span class="md-nav__icon md-icon"></span> Logical Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../logical-operators/EventTimeWatermark/ class=md-nav__link> EventTimeWatermark </a> </li> <li class=md-nav__item> <a href=../../logical-operators/FlatMapGroupsWithState/ class=md-nav__link> FlatMapGroupsWithState </a> </li> <li class=md-nav__item> <a href=../../logical-operators/Deduplicate/ class=md-nav__link> Deduplicate </a> </li> <li class=md-nav__item> <a href=../../logical-operators/StreamingDataSourceV2Relation/ class=md-nav__link> StreamingDataSourceV2Relation </a> </li> <li class=md-nav__item> <a href=../../logical-operators/StreamingRelation/ class=md-nav__link> StreamingRelation </a> </li> <li class=md-nav__item> <a href=../../logical-operators/StreamingRelationV2/ class=md-nav__link> StreamingRelationV2 </a> </li> <li class=md-nav__item> <a href=../../logical-operators/StreamingExecutionRelation/ class=md-nav__link> StreamingExecutionRelation </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-22 type=checkbox id=nav-2-22> <label class=md-nav__link for=nav-2-22> Physical Operators <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Physical Operators" data-md-level=2> <label class=md-nav__title for=nav-2-22> <span class="md-nav__icon md-icon"></span> Physical Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../physical-operators/MicroBatchScanExec/ class=md-nav__link> MicroBatchScanExec </a> </li> <li class=md-nav__item> <a href=../../physical-operators/EventTimeWatermarkExec/ class=md-nav__link> EventTimeWatermarkExec </a> </li> <li class=md-nav__item> <a href=../../physical-operators/FlatMapGroupsWithStateExec/ class=md-nav__link> FlatMapGroupsWithStateExec </a> </li> <li class=md-nav__item> <a href=../../physical-operators/StatefulOperator/ class=md-nav__link> StatefulOperator </a> </li> <li class=md-nav__item> <a href=../../physical-operators/StateStoreReader/ class=md-nav__link> StateStoreReader </a> </li> <li class=md-nav__item> <a href=../../physical-operators/StateStoreRestoreExec/ class=md-nav__link> StateStoreRestoreExec </a> </li> <li class=md-nav__item> <a href=../../physical-operators/StateStoreSaveExec/ class=md-nav__link> StateStoreSaveExec </a> </li> <li class=md-nav__item> <a href=../../physical-operators/StateStoreWriter/ class=md-nav__link> StateStoreWriter </a> </li> <li class=md-nav__item> <a href=../../physical-operators/StreamingDeduplicateExec/ class=md-nav__link> StreamingDeduplicateExec </a> </li> <li class=md-nav__item> <a href=../../physical-operators/StreamingGlobalLimitExec/ class=md-nav__link> StreamingGlobalLimitExec </a> </li> <li class=md-nav__item> <a href=../../physical-operators/StreamingRelationExec/ class=md-nav__link> StreamingRelationExec </a> </li> <li class=md-nav__item> <a href=../../physical-operators/StreamingSymmetricHashJoinExec/ class=md-nav__link> StreamingSymmetricHashJoinExec </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-23 type=checkbox id=nav-2-23> <label class=md-nav__link for=nav-2-23> Execution Planning Strategies <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Execution Planning Strategies" data-md-level=2> <label class=md-nav__title for=nav-2-23> <span class="md-nav__icon md-icon"></span> Execution Planning Strategies </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../FlatMapGroupsWithStateStrategy/ class=md-nav__link> FlatMapGroupsWithStateStrategy </a> </li> <li class=md-nav__item> <a href=../../StatefulAggregationStrategy/ class=md-nav__link> StatefulAggregationStrategy </a> </li> <li class=md-nav__item> <a href=../../StreamingDeduplicationStrategy/ class=md-nav__link> StreamingDeduplicationStrategy </a> </li> <li class=md-nav__item> <a href=../../StreamingGlobalLimitStrategy/ class=md-nav__link> StreamingGlobalLimitStrategy </a> </li> <li class=md-nav__item> <a href=../../StreamingJoinStrategy/ class=md-nav__link> StreamingJoinStrategy </a> </li> <li class=md-nav__item> <a href=../../StreamingRelationStrategy/ class=md-nav__link> StreamingRelationStrategy </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-24 type=checkbox id=nav-2-24> <label class=md-nav__link for=nav-2-24> Offsets and Metadata Checkpointing <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Offsets and Metadata Checkpointing" data-md-level=2> <label class=md-nav__title for=nav-2-24> <span class="md-nav__icon md-icon"></span> Offsets and Metadata Checkpointing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../offsets-and-metadata-checkpointing/ class=md-nav__link> Offsets and Metadata Checkpointing </a> </li> <li class=md-nav__item> <a href=../../MetadataLog/ class=md-nav__link> MetadataLog </a> </li> <li class=md-nav__item> <a href=../../HDFSMetadataLog/ class=md-nav__link> HDFSMetadataLog </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-24-4 type=checkbox id=nav-2-24-4> <label class=md-nav__link for=nav-2-24-4> CommitLog <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=CommitLog data-md-level=3> <label class=md-nav__title for=nav-2-24-4> <span class="md-nav__icon md-icon"></span> CommitLog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../CommitLog/ class=md-nav__link> CommitLog </a> </li> <li class=md-nav__item> <a href=../../CommitMetadata/ class=md-nav__link> CommitMetadata </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-24-5 type=checkbox id=nav-2-24-5> <label class=md-nav__link for=nav-2-24-5> OffsetSeqLog <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=OffsetSeqLog data-md-level=3> <label class=md-nav__title for=nav-2-24-5> <span class="md-nav__icon md-icon"></span> OffsetSeqLog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../OffsetSeqLog/ class=md-nav__link> OffsetSeqLog </a> </li> <li class=md-nav__item> <a href=../../OffsetSeq/ class=md-nav__link> OffsetSeq </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../OffsetSeqMetadata/ class=md-nav__link> OffsetSeqMetadata </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-24-7 type=checkbox id=nav-2-24-7> <label class=md-nav__link for=nav-2-24-7> CheckpointFileManager <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=CheckpointFileManager data-md-level=3> <label class=md-nav__title for=nav-2-24-7> <span class="md-nav__icon md-icon"></span> CheckpointFileManager </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../CheckpointFileManager/ class=md-nav__link> CheckpointFileManager </a> </li> <li class=md-nav__item> <a href=../../FileContextBasedCheckpointFileManager/ class=md-nav__link> FileContextBasedCheckpointFileManager </a> </li> <li class=md-nav__item> <a href=../../FileSystemBasedCheckpointFileManager/ class=md-nav__link> FileSystemBasedCheckpointFileManager </a> </li> <li class=md-nav__item> <a href=../../Offset/ class=md-nav__link> Offset </a> </li> <li class=md-nav__item> <a href=../../StreamProgress/ class=md-nav__link> StreamProgress </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-25 type=checkbox id=nav-2-25 checked> <div class="md-nav__link md-nav__link--container "> <a href=../ >Micro-Batch Execution</a> <label for=nav-2-25> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Micro-Batch Execution" data-md-level=2> <label class=md-nav__title for=nav-2-25> <span class="md-nav__icon md-icon"></span> Micro-Batch Execution </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> MicroBatchExecution <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> MicroBatchExecution </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#creating-instance class=md-nav__link> Creating Instance </a> </li> <li class=md-nav__item> <a href=#streaming-sources-registry class=md-nav__link> Streaming Sources Registry </a> </li> <li class=md-nav__item> <a href=#triggerexecutor class=md-nav__link> TriggerExecutor </a> </li> <li class=md-nav__item> <a href=#running-activated-streaming-query class=md-nav__link> Running Activated Streaming Query </a> <nav class=md-nav aria-label=" Running Activated Streaming Query"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#triggerexecutors-batch-runner class=md-nav__link> TriggerExecutor's Batch Runner </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#populating-start-offsets-from-checkpoint-resuming-from-checkpoint class=md-nav__link> Populating Start Offsets From Checkpoint (Resuming from Checkpoint) </a> <nav class=md-nav aria-label=" Populating Start Offsets From Checkpoint (Resuming from Checkpoint)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#latest-committed-batch-available class=md-nav__link> Latest Committed Batch Available </a> </li> <li class=md-nav__item> <a href=#no-latest-committed-batch class=md-nav__link> No Latest Committed Batch </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#constructing-or-skipping-next-streaming-micro-batch class=md-nav__link> Constructing Or Skipping Next Streaming Micro-Batch </a> <nav class=md-nav aria-label=" Constructing Or Skipping Next Streaming Micro-Batch"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#requesting-latest-offsets-from-streaming-sources-getoffset-setoffsetrange-and-getendoffset-phases class=md-nav__link> Requesting Latest Offsets from Streaming Sources (getOffset, setOffsetRange and getEndOffset Phases) </a> </li> <li class=md-nav__item> <a href=#getoffset-phase class=md-nav__link> getOffset Phase </a> </li> <li class=md-nav__item> <a href=#setoffsetrange-phase class=md-nav__link> setOffsetRange Phase </a> </li> <li class=md-nav__item> <a href=#getendoffset-phase class=md-nav__link> getEndOffset Phase </a> </li> <li class=md-nav__item> <a href=#updating-availableoffsets-streamprogress-with-latest-available-offsets class=md-nav__link> Updating availableOffsets StreamProgress with Latest Available Offsets </a> </li> <li class=md-nav__item> <a href=#updating-batch-metadata-with-current-event-time-watermark-and-batch-timestamp class=md-nav__link> Updating Batch Metadata with Current Event-Time Watermark and Batch Timestamp </a> </li> <li class=md-nav__item> <a href=#checking-whether-to-construct-next-micro-batch-or-not-skip-it class=md-nav__link> Checking Whether to Construct Next Micro-Batch or Not (Skip It) </a> </li> <li class=md-nav__item> <a href=#constructing-next-micro-batch class=md-nav__link> Constructing Next Micro-Batch </a> </li> <li class=md-nav__item> <a href=#skipping-next-micro-batch class=md-nav__link> Skipping Next Micro-Batch </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#running-single-streaming-micro-batch class=md-nav__link> Running Single Streaming Micro-Batch </a> <nav class=md-nav aria-label=" Running Single Streaming Micro-Batch"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#getbatch-phase-creating-logical-query-plans-for-unprocessed-data-from-sources-and-microbatchreaders class=md-nav__link> getBatch Phase -- Creating Logical Query Plans For Unprocessed Data From Sources and MicroBatchReaders </a> </li> <li class=md-nav__item> <a href=#getbatch-phase-and-sources class=md-nav__link> getBatch Phase and Sources </a> </li> <li class=md-nav__item> <a href=#getbatch-phase-and-microbatchreaders class=md-nav__link> getBatch Phase and MicroBatchReaders </a> </li> <li class=md-nav__item> <a href=#transforming-logical-plan-to-include-sources-and-microbatchreaders-with-new-data class=md-nav__link> Transforming Logical Plan to Include Sources and MicroBatchReaders with New Data </a> </li> <li class=md-nav__item> <a href=#transforming-currenttimestamp-and-currentdate-expressions-per-batch-metadata class=md-nav__link> Transforming CurrentTimestamp and CurrentDate Expressions (Per Batch Metadata) </a> </li> <li class=md-nav__item> <a href=#adapting-transformed-logical-plan-to-sink-with-streamwritesupport class=md-nav__link> Adapting Transformed Logical Plan to Sink with StreamWriteSupport </a> </li> <li class=md-nav__item> <a href=#setting-local-properties class=md-nav__link> Setting Local Properties </a> </li> <li class=md-nav__item> <a href=#queryplanning-phase-creating-and-preparing-incrementalexecution-for-execution class=md-nav__link> queryPlanning Phase -- Creating and Preparing IncrementalExecution for Execution </a> </li> <li class=md-nav__item> <a href=#nextbatch-phase-creating-dataframe-with-incrementalexecution-for-new-data class=md-nav__link> nextBatch Phase &mdash; Creating DataFrame (with IncrementalExecution for New Data) </a> </li> <li class=md-nav__item> <a href=#addbatch-phase-adding-dataframe-with-new-data-to-sink class=md-nav__link> addBatch Phase &mdash; Adding DataFrame With New Data to Sink </a> </li> <li class=md-nav__item> <a href=#updating-watermark-and-committing-offsets-to-offset-commit-log class=md-nav__link> Updating Watermark and Committing Offsets to Offset Commit Log </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#stopping-stream-processing-execution-of-streaming-query class=md-nav__link> Stopping Stream Processing (Execution of Streaming Query) </a> </li> <li class=md-nav__item> <a href=#checking-whether-new-data-is-available class=md-nav__link> Checking Whether New Data Is Available </a> </li> <li class=md-nav__item> <a href=#analyzed-logical-plan class=md-nav__link> Analyzed Logical Plan </a> </li> <li class=md-nav__item> <a href=#streamingsqlbatchid-local-property class=md-nav__link> streaming.sql.batchId Local Property </a> </li> <li class=md-nav__item> <a href=#watermarktracker class=md-nav__link> WatermarkTracker </a> </li> <li class=md-nav__item> <a href=#iscurrentbatchconstructed-flag class=md-nav__link> isCurrentBatchConstructed Flag </a> </li> <li class=md-nav__item> <a href=#demo class=md-nav__link> Demo </a> </li> <li class=md-nav__item> <a href=#logging class=md-nav__link> Logging </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../MicroBatchWriter/ class=md-nav__link> MicroBatchWriter </a> </li> <li class=md-nav__item> <a href=../MicroBatchReader/ class=md-nav__link> MicroBatchReader </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-25-5 type=checkbox id=nav-2-25-5> <label class=md-nav__link for=nav-2-25-5> Source <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Source data-md-level=3> <label class=md-nav__title for=nav-2-25-5> <span class="md-nav__icon md-icon"></span> Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Source/ class=md-nav__link> Source </a> </li> <li class=md-nav__item> <a href=../../StreamSourceProvider/ class=md-nav__link> StreamSourceProvider </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../Sink/ class=md-nav__link> Sink </a> </li> <li class=md-nav__item> <a href=../../StreamSinkProvider/ class=md-nav__link> StreamSinkProvider </a> </li> <li class=md-nav__item> <a href=../../WatermarkTracker/ class=md-nav__link> WatermarkTracker </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-26 type=checkbox id=nav-2-26> <label class=md-nav__link for=nav-2-26> Continuous Stream Processing <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Continuous Stream Processing" data-md-level=2> <label class=md-nav__title for=nav-2-26> <span class="md-nav__icon md-icon"></span> Continuous Stream Processing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../continuous-stream-processing/ class=md-nav__link> Continuous Stream Processing </a> </li> <li class=md-nav__item> <a href=../../ContinuousExecution/ class=md-nav__link> ContinuousExecution </a> </li> <li class=md-nav__item> <a href=../../ContinuousReadSupport/ class=md-nav__link> ContinuousReadSupport </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-ContinuousReader/ class=md-nav__link> ContinuousReader </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-RateStreamContinuousReader/ class=md-nav__link> RateStreamContinuousReader </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-26-6 type=checkbox id=nav-2-26-6> <label class=md-nav__link for=nav-2-26-6> EpochCoordinator <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=EpochCoordinator data-md-level=3> <label class=md-nav__title for=nav-2-26-6> <span class="md-nav__icon md-icon"></span> EpochCoordinator </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../spark-sql-streaming-EpochCoordinator/ class=md-nav__link> EpochCoordinator RPC Endpoint </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-EpochCoordinatorRef/ class=md-nav__link> EpochCoordinatorRef </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-EpochTracker/ class=md-nav__link> EpochTracker </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-26-7 type=checkbox id=nav-2-26-7> <label class=md-nav__link for=nav-2-26-7> ContinuousQueuedDataReader <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=ContinuousQueuedDataReader data-md-level=3> <label class=md-nav__title for=nav-2-26-7> <span class="md-nav__icon md-icon"></span> ContinuousQueuedDataReader </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../spark-sql-streaming-ContinuousQueuedDataReader/ class=md-nav__link> ContinuousQueuedDataReader </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-ContinuousQueuedDataReader-DataReaderThread/ class=md-nav__link> DataReaderThread </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-ContinuousQueuedDataReader-EpochMarkerGenerator/ class=md-nav__link> EpochMarkerGenerator </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-PartitionOffset/ class=md-nav__link> PartitionOffset </a> </li> <li class=md-nav__item> <a href=../../ContinuousExecutionRelation/ class=md-nav__link> ContinuousExecutionRelation </a> </li> <li class=md-nav__item> <a href=../../WriteToContinuousDataSource/ class=md-nav__link> WriteToContinuousDataSource </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-26-11 type=checkbox id=nav-2-26-11> <label class=md-nav__link for=nav-2-26-11> WriteToContinuousDataSourceExec <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=WriteToContinuousDataSourceExec data-md-level=3> <label class=md-nav__title for=nav-2-26-11> <span class="md-nav__icon md-icon"></span> WriteToContinuousDataSourceExec </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../spark-sql-streaming-WriteToContinuousDataSourceExec/ class=md-nav__link> WriteToContinuousDataSourceExec Unary Physical Operator </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-ContinuousWriteRDD/ class=md-nav__link> ContinuousWriteRDD </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-ContinuousDataSourceRDD/ class=md-nav__link> ContinuousDataSourceRDD </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../UnsupportedOperationChecker/ class=md-nav__link> UnsupportedOperationChecker </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-extending-new-data-sources/ class=md-nav__link> Extending Structured Streaming with New Data Sources </a> </li> <li class=md-nav__item> <a href=../../SQLConf/ class=md-nav__link> SQLConf </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <div class="md-nav__link md-nav__link--container "> <a href=../../operators/ >Streaming Operators</a> <label for=nav-3> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Streaming Operators" data-md-level=1> <label class=md-nav__title for=nav-3> <span class="md-nav__icon md-icon"></span> Streaming Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../operators/crossJoin/ class=md-nav__link> crossJoin </a> </li> <li class=md-nav__item> <a href=../../operators/dropDuplicates/ class=md-nav__link> dropDuplicates </a> </li> <li class=md-nav__item> <a href=../../operators/explain/ class=md-nav__link> explain </a> </li> <li class=md-nav__item> <a href=../../operators/flatMapGroupsWithState/ class=md-nav__link> flatMapGroupsWithState </a> </li> <li class=md-nav__item> <a href=../../operators/groupBy/ class=md-nav__link> groupBy </a> </li> <li class=md-nav__item> <a href=../../operators/groupByKey/ class=md-nav__link> groupByKey </a> </li> <li class=md-nav__item> <a href=../../operators/join/ class=md-nav__link> join </a> </li> <li class=md-nav__item> <a href=../../operators/joinWith/ class=md-nav__link> joinWith </a> </li> <li class=md-nav__item> <a href=../../operators/withWatermark/ class=md-nav__link> withWatermark </a> </li> <li class=md-nav__item> <a href=../../operators/writeStream/ class=md-nav__link> writeStream </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4 type=checkbox id=nav-4> <div class="md-nav__link md-nav__link--container "> <a href=../../datasources/ >Data Sources</a> <label for=nav-4> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Data Sources" data-md-level=1> <label class=md-nav__title for=nav-4> <span class="md-nav__icon md-icon"></span> Data Sources </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-2 type=checkbox id=nav-4-2> <div class="md-nav__link md-nav__link--container "> <a href=../../datasources/file/ >File</a> <label for=nav-4-2> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=File data-md-level=2> <label class=md-nav__title for=nav-4-2> <span class="md-nav__icon md-icon"></span> File </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../datasources/file/FileStreamSource/ class=md-nav__link> FileStreamSource </a> </li> <li class=md-nav__item> <a href=../../datasources/file/FileStreamSink/ class=md-nav__link> FileStreamSink </a> </li> <li class=md-nav__item> <a href=../../datasources/file/CompactibleFileStreamLog/ class=md-nav__link> CompactibleFileStreamLog </a> </li> <li class=md-nav__item> <a href=../../datasources/file/SinkFileStatus/ class=md-nav__link> SinkFileStatus </a> </li> <li class=md-nav__item> <a href=../../datasources/file/ManifestFileCommitProtocol/ class=md-nav__link> ManifestFileCommitProtocol </a> </li> <li class=md-nav__item> <a href=../../datasources/file/MetadataLogFileIndex/ class=md-nav__link> MetadataLogFileIndex </a> </li> <li class=md-nav__item> <a href=../../datasources/file/FileStreamSourceCleaner/ class=md-nav__link> FileStreamSourceCleaner </a> </li> <li class=md-nav__item> <a href=../../datasources/file/FileStreamSourceLog/ class=md-nav__link> FileStreamSourceLog </a> </li> <li class=md-nav__item> <a href=../../datasources/file/FileStreamSinkLog/ class=md-nav__link> FileStreamSinkLog </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-3 type=checkbox id=nav-4-3> <div class="md-nav__link md-nav__link--container "> <a href=../../datasources/kafka/ >Kafka</a> <label for=nav-4-3> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=Kafka data-md-level=2> <label class=md-nav__title for=nav-4-3> <span class="md-nav__icon md-icon"></span> Kafka </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaSourceProvider/ class=md-nav__link> KafkaSourceProvider </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaMicroBatchStream/ class=md-nav__link> KafkaMicroBatchStream </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaTable/ class=md-nav__link> KafkaTable </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaSource/ class=md-nav__link> KafkaSource </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaRelation/ class=md-nav__link> KafkaRelation </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaSourceRDD/ class=md-nav__link> KafkaSourceRDD </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/CachedKafkaConsumer/ class=md-nav__link> CachedKafkaConsumer </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaSourceOffset/ class=md-nav__link> KafkaSourceOffset </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaOffsetReader/ class=md-nav__link> KafkaOffsetReader </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/ConsumerStrategy/ class=md-nav__link> ConsumerStrategy </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaSink/ class=md-nav__link> KafkaSink </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaBatch/ class=md-nav__link> KafkaBatch </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaScan/ class=md-nav__link> KafkaScan </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaOffsetRangeLimit/ class=md-nav__link> KafkaOffsetRangeLimit </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaDataConsumer/ class=md-nav__link> KafkaDataConsumer </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-3-17 type=checkbox id=nav-4-3-17> <label class=md-nav__link for=nav-4-3-17> KafkaMicroBatchReader <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=KafkaMicroBatchReader data-md-level=3> <label class=md-nav__title for=nav-4-3-17> <span class="md-nav__icon md-icon"></span> KafkaMicroBatchReader </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaMicroBatchReader/ class=md-nav__link> KafkaMicroBatchReader </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaOffsetRangeCalculator/ class=md-nav__link> KafkaOffsetRangeCalculator </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaMicroBatchInputPartition/ class=md-nav__link> KafkaMicroBatchInputPartition </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaMicroBatchInputPartitionReader/ class=md-nav__link> KafkaMicroBatchInputPartitionReader </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaSourceInitialOffsetWriter/ class=md-nav__link> KafkaSourceInitialOffsetWriter </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-3-18 type=checkbox id=nav-4-3-18> <label class=md-nav__link for=nav-4-3-18> KafkaContinuousReader <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=KafkaContinuousReader data-md-level=3> <label class=md-nav__title for=nav-4-3-18> <span class="md-nav__icon md-icon"></span> KafkaContinuousReader </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaContinuousReader/ class=md-nav__link> KafkaContinuousReader </a> </li> <li class=md-nav__item> <a href=../../datasources/kafka/KafkaContinuousInputPartition/ class=md-nav__link> KafkaContinuousInputPartition </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-4 type=checkbox id=nav-4-4> <div class="md-nav__link md-nav__link--container "> <a href=../../datasources/socket/ >Text Socket</a> <label for=nav-4-4> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Text Socket" data-md-level=2> <label class=md-nav__title for=nav-4-4> <span class="md-nav__icon md-icon"></span> Text Socket </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../datasources/socket/TextSocketSourceProvider/ class=md-nav__link> TextSocketSourceProvider </a> </li> <li class=md-nav__item> <a href=../../datasources/socket/TextSocketSource/ class=md-nav__link> TextSocketSource </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-5 type=checkbox id=nav-4-5> <label class=md-nav__link for=nav-4-5> Rate <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Rate data-md-level=2> <label class=md-nav__title for=nav-4-5> <span class="md-nav__icon md-icon"></span> Rate </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../spark-sql-streaming-RateSourceProvider/ class=md-nav__link> RateSourceProvider </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-RateStreamProvider/ class=md-nav__link> RateStreamProvider </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-RateStreamSource/ class=md-nav__link> RateStreamSource </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-RateStreamMicroBatchReader/ class=md-nav__link> RateStreamMicroBatchReader </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-6 type=checkbox id=nav-4-6> <label class=md-nav__link for=nav-4-6> Console Sink <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Console Sink" data-md-level=2> <label class=md-nav__title for=nav-4-6> <span class="md-nav__icon md-icon"></span> Console Sink </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../spark-sql-streaming-ConsoleSinkProvider/ class=md-nav__link> ConsoleSinkProvider </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-ConsoleWriter/ class=md-nav__link> ConsoleWriter </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-7 type=checkbox id=nav-4-7> <label class=md-nav__link for=nav-4-7> Foreach Sink <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Foreach Sink" data-md-level=2> <label class=md-nav__title for=nav-4-7> <span class="md-nav__icon md-icon"></span> Foreach Sink </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../datasources/ForeachWriterProvider/ class=md-nav__link> ForeachWriterProvider </a> </li> <li class=md-nav__item> <a href=../../datasources/ForeachWriter/ class=md-nav__link> ForeachWriter </a> </li> <li class=md-nav__item> <a href=../../datasources/ForeachSink/ class=md-nav__link> ForeachSink </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-8 type=checkbox id=nav-4-8> <label class=md-nav__link for=nav-4-8> ForeachBatch Sink <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="ForeachBatch Sink" data-md-level=2> <label class=md-nav__title for=nav-4-8> <span class="md-nav__icon md-icon"></span> ForeachBatch Sink </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../datasources/ForeachBatchSink/ class=md-nav__link> ForeachBatchSink </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-9 type=checkbox id=nav-4-9> <div class="md-nav__link md-nav__link--container "> <a href=../../datasources/memory/ >Memory</a> <label for=nav-4-9> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=Memory data-md-level=2> <label class=md-nav__title for=nav-4-9> <span class="md-nav__icon md-icon"></span> Memory </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../datasources/memory/MemoryStream/ class=md-nav__link> MemoryStream </a> </li> <li class=md-nav__item> <a href=../../datasources/memory/ContinuousMemoryStream/ class=md-nav__link> ContinuousMemoryStream </a> </li> <li class=md-nav__item> <a href=../../datasources/memory/MemorySink/ class=md-nav__link> MemorySink </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-9-5 type=checkbox id=nav-4-9-5> <label class=md-nav__link for=nav-4-9-5> MemorySinkV2 <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=MemorySinkV2 data-md-level=3> <label class=md-nav__title for=nav-4-9-5> <span class="md-nav__icon md-icon"></span> MemorySinkV2 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../datasources/memory/MemorySinkV2/ class=md-nav__link> MemorySinkV2 </a> </li> <li class=md-nav__item> <a href=../../spark-sql-streaming-MemoryStreamWriter/ class=md-nav__link> MemoryStreamWriter </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../datasources/memory/MemoryStreamBase/ class=md-nav__link> MemoryStreamBase </a> </li> <li class=md-nav__item> <a href=../../datasources/memory/MemorySinkBase/ class=md-nav__link> MemorySinkBase </a> </li> <li class=md-nav__item> <a href=../../datasources/memory/MemoryPlan/ class=md-nav__link> MemoryPlan </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-5 type=checkbox id=nav-5> <label class=md-nav__link for=nav-5> Monitoring <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Monitoring data-md-level=1> <label class=md-nav__title for=nav-5> <span class="md-nav__icon md-icon"></span> Monitoring </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../monitoring/StreamingQueryListener/ class=md-nav__link> StreamingQueryListener </a> </li> <li class=md-nav__item> <a href=../../monitoring/ProgressReporter/ class=md-nav__link> ProgressReporter </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-5-3 type=checkbox id=nav-5-3> <label class=md-nav__link for=nav-5-3> StreamingQueryProgress <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StreamingQueryProgress data-md-level=2> <label class=md-nav__title for=nav-5-3> <span class="md-nav__icon md-icon"></span> StreamingQueryProgress </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../monitoring/StreamingQueryProgress/ class=md-nav__link> StreamingQueryProgress </a> </li> <li class=md-nav__item> <a href=../../monitoring/StateOperatorProgress/ class=md-nav__link> StateOperatorProgress </a> </li> <li class=md-nav__item> <a href=../../monitoring/ExecutionStats/ class=md-nav__link> ExecutionStats </a> </li> <li class=md-nav__item> <a href=../../monitoring/SourceProgress/ class=md-nav__link> SourceProgress </a> </li> <li class=md-nav__item> <a href=../../monitoring/SinkProgress/ class=md-nav__link> SinkProgress </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../monitoring/StreamingQueryStatus/ class=md-nav__link> StreamingQueryStatus </a> </li> <li class=md-nav__item> <a href=../../monitoring/MetricsReporter/ class=md-nav__link> MetricsReporter </a> </li> <li class=md-nav__item> <a href=../../spark-logging/ class=md-nav__link> Logging </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-6 type=checkbox id=nav-6> <label class=md-nav__link for=nav-6> Web UI <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Web UI" data-md-level=1> <label class=md-nav__title for=nav-6> <span class="md-nav__icon md-icon"></span> Web UI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../webui/ class=md-nav__link> Web UI </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-7 type=checkbox id=nav-7> <div class="md-nav__link md-nav__link--container "> <a href=../../demo/ >Demos</a> <label for=nav-7> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=Demos data-md-level=1> <label class=md-nav__title for=nav-7> <span class="md-nav__icon md-icon"></span> Demos </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../demo/spark-sql-streaming-demo-FlatMapGroupsWithStateExec/ class=md-nav__link> Internals of FlatMapGroupsWithStateExec Physical Operator </a> </li> <li class=md-nav__item> <a href=../../demo/arbitrary-stateful-streaming-aggregation-flatMapGroupsWithState/ class=md-nav__link> Arbitrary Stateful Streaming Aggregation with KeyValueGroupedDataset.flatMapGroupsWithState Operator </a> </li> <li class=md-nav__item> <a href=../../demo/exploring-checkpointed-state/ class=md-nav__link> Exploring Checkpointed State </a> </li> <li class=md-nav__item> <a href=../../demo/watermark-aggregation-append/ class=md-nav__link> Streaming Watermark with Aggregation in Append Output Mode </a> </li> <li class=md-nav__item> <a href=../../demo/groupBy-running-count-complete/ class=md-nav__link> Streaming Query for Running Counts (Socket Source and Complete Output Mode) </a> </li> <li class=md-nav__item> <a href=../../demo/kafka-data-source/ class=md-nav__link> Streaming Aggregation with Kafka Data Source </a> </li> <li class=md-nav__item> <a href=../../demo/groupByKey-count-Update/ class=md-nav__link> groupByKey Streaming Aggregation in Update Mode </a> </li> <li class=md-nav__item> <a href=../../demo/StateStoreSaveExec-Complete/ class=md-nav__link> StateStoreSaveExec with Complete Output Mode </a> </li> <li class=md-nav__item> <a href=../../demo/StateStoreSaveExec-Update/ class=md-nav__link> StateStoreSaveExec with Update Output Mode </a> </li> <li class=md-nav__item> <a href=../../demo/custom-sink-webui/ class=md-nav__link> Developing Custom Streaming Sink (and Monitoring SQL Queries in web UI) </a> </li> <li class=md-nav__item> <a href=../../demo/current_timestamp/ class=md-nav__link> current_timestamp Function For Processing Time in Streaming Queries </a> </li> <li class=md-nav__item> <a href=../../demo/StreamingQueryManager-awaitAnyTermination-resetTerminated/ class=md-nav__link> Using StreamingQueryManager for Query Termination Management </a> </li> <li class=md-nav__item> <a href=../../demo/using-file-streaming-source/ class=md-nav__link> Using File Streaming Source </a> </li> <li class=md-nav__item> <a href=../../demo/deep-dive-into-filestreamsink/ class=md-nav__link> Deep Dive into FileStreamSink </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#creating-instance class=md-nav__link> Creating Instance </a> </li> <li class=md-nav__item> <a href=#streaming-sources-registry class=md-nav__link> Streaming Sources Registry </a> </li> <li class=md-nav__item> <a href=#triggerexecutor class=md-nav__link> TriggerExecutor </a> </li> <li class=md-nav__item> <a href=#running-activated-streaming-query class=md-nav__link> Running Activated Streaming Query </a> <nav class=md-nav aria-label=" Running Activated Streaming Query"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#triggerexecutors-batch-runner class=md-nav__link> TriggerExecutor's Batch Runner </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#populating-start-offsets-from-checkpoint-resuming-from-checkpoint class=md-nav__link> Populating Start Offsets From Checkpoint (Resuming from Checkpoint) </a> <nav class=md-nav aria-label=" Populating Start Offsets From Checkpoint (Resuming from Checkpoint)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#latest-committed-batch-available class=md-nav__link> Latest Committed Batch Available </a> </li> <li class=md-nav__item> <a href=#no-latest-committed-batch class=md-nav__link> No Latest Committed Batch </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#constructing-or-skipping-next-streaming-micro-batch class=md-nav__link> Constructing Or Skipping Next Streaming Micro-Batch </a> <nav class=md-nav aria-label=" Constructing Or Skipping Next Streaming Micro-Batch"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#requesting-latest-offsets-from-streaming-sources-getoffset-setoffsetrange-and-getendoffset-phases class=md-nav__link> Requesting Latest Offsets from Streaming Sources (getOffset, setOffsetRange and getEndOffset Phases) </a> </li> <li class=md-nav__item> <a href=#getoffset-phase class=md-nav__link> getOffset Phase </a> </li> <li class=md-nav__item> <a href=#setoffsetrange-phase class=md-nav__link> setOffsetRange Phase </a> </li> <li class=md-nav__item> <a href=#getendoffset-phase class=md-nav__link> getEndOffset Phase </a> </li> <li class=md-nav__item> <a href=#updating-availableoffsets-streamprogress-with-latest-available-offsets class=md-nav__link> Updating availableOffsets StreamProgress with Latest Available Offsets </a> </li> <li class=md-nav__item> <a href=#updating-batch-metadata-with-current-event-time-watermark-and-batch-timestamp class=md-nav__link> Updating Batch Metadata with Current Event-Time Watermark and Batch Timestamp </a> </li> <li class=md-nav__item> <a href=#checking-whether-to-construct-next-micro-batch-or-not-skip-it class=md-nav__link> Checking Whether to Construct Next Micro-Batch or Not (Skip It) </a> </li> <li class=md-nav__item> <a href=#constructing-next-micro-batch class=md-nav__link> Constructing Next Micro-Batch </a> </li> <li class=md-nav__item> <a href=#skipping-next-micro-batch class=md-nav__link> Skipping Next Micro-Batch </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#running-single-streaming-micro-batch class=md-nav__link> Running Single Streaming Micro-Batch </a> <nav class=md-nav aria-label=" Running Single Streaming Micro-Batch"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#getbatch-phase-creating-logical-query-plans-for-unprocessed-data-from-sources-and-microbatchreaders class=md-nav__link> getBatch Phase -- Creating Logical Query Plans For Unprocessed Data From Sources and MicroBatchReaders </a> </li> <li class=md-nav__item> <a href=#getbatch-phase-and-sources class=md-nav__link> getBatch Phase and Sources </a> </li> <li class=md-nav__item> <a href=#getbatch-phase-and-microbatchreaders class=md-nav__link> getBatch Phase and MicroBatchReaders </a> </li> <li class=md-nav__item> <a href=#transforming-logical-plan-to-include-sources-and-microbatchreaders-with-new-data class=md-nav__link> Transforming Logical Plan to Include Sources and MicroBatchReaders with New Data </a> </li> <li class=md-nav__item> <a href=#transforming-currenttimestamp-and-currentdate-expressions-per-batch-metadata class=md-nav__link> Transforming CurrentTimestamp and CurrentDate Expressions (Per Batch Metadata) </a> </li> <li class=md-nav__item> <a href=#adapting-transformed-logical-plan-to-sink-with-streamwritesupport class=md-nav__link> Adapting Transformed Logical Plan to Sink with StreamWriteSupport </a> </li> <li class=md-nav__item> <a href=#setting-local-properties class=md-nav__link> Setting Local Properties </a> </li> <li class=md-nav__item> <a href=#queryplanning-phase-creating-and-preparing-incrementalexecution-for-execution class=md-nav__link> queryPlanning Phase -- Creating and Preparing IncrementalExecution for Execution </a> </li> <li class=md-nav__item> <a href=#nextbatch-phase-creating-dataframe-with-incrementalexecution-for-new-data class=md-nav__link> nextBatch Phase &mdash; Creating DataFrame (with IncrementalExecution for New Data) </a> </li> <li class=md-nav__item> <a href=#addbatch-phase-adding-dataframe-with-new-data-to-sink class=md-nav__link> addBatch Phase &mdash; Adding DataFrame With New Data to Sink </a> </li> <li class=md-nav__item> <a href=#updating-watermark-and-committing-offsets-to-offset-commit-log class=md-nav__link> Updating Watermark and Committing Offsets to Offset Commit Log </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#stopping-stream-processing-execution-of-streaming-query class=md-nav__link> Stopping Stream Processing (Execution of Streaming Query) </a> </li> <li class=md-nav__item> <a href=#checking-whether-new-data-is-available class=md-nav__link> Checking Whether New Data Is Available </a> </li> <li class=md-nav__item> <a href=#analyzed-logical-plan class=md-nav__link> Analyzed Logical Plan </a> </li> <li class=md-nav__item> <a href=#streamingsqlbatchid-local-property class=md-nav__link> streaming.sql.batchId Local Property </a> </li> <li class=md-nav__item> <a href=#watermarktracker class=md-nav__link> WatermarkTracker </a> </li> <li class=md-nav__item> <a href=#iscurrentbatchconstructed-flag class=md-nav__link> isCurrentBatchConstructed Flag </a> </li> <li class=md-nav__item> <a href=#demo class=md-nav__link> Demo </a> </li> <li class=md-nav__item> <a href=#logging class=md-nav__link> Logging </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <a href=https://github.com/jaceklaskowski/spark-structured-streaming-book/edit/main/docs/micro-batch-execution/MicroBatchExecution.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1 id=microbatchexecution>MicroBatchExecution<a class=headerlink href=#microbatchexecution title="Permanent link">&para;</a></h1> <p><code>MicroBatchExecution</code> is a <a href=../../StreamExecution/ >stream execution engine</a> for <a href=../ >Micro-Batch Stream Processing</a>.</p> <h2 id=creating-instance>Creating Instance<a class=headerlink href=#creating-instance title="Permanent link">&para;</a></h2> <p><code>MicroBatchExecution</code> takes the following to be created:</p> <ul> <li><span id=sparkSession> <code>SparkSession</code> (<a href=https://jaceklaskowski.github.io/mastering-spark-sql-book/SparkSession>Spark SQL</a>)</li> <li><span id=name> Name of the streaming query</li> <li><span id=checkpointRoot> Path of the Checkpoint Directory</li> <li><span id=analyzedPlan> Analyzed logical query plan of the streaming query (<a href=https://jaceklaskowski.github.io/mastering-spark-sql-book/logical-operators/LogicalPlan>Spark SQL</a>)</li> <li><span id=sink> <code>Table</code> Sink (<a href=https://jaceklaskowski.github.io/mastering-spark-sql-book/connector/Table>Spark SQL</a>)</li> <li><span id=trigger> <a href=../../Trigger/ >Trigger</a></li> <li><span id=triggerClock> <code>Clock</code></li> <li><span id=outputMode> <a href=../../OutputMode/ >OutputMode</a></li> <li><span id=extraOptions> Extra Options (<code>Map[String, String]</code>)</li> <li><span id=deleteCheckpointOnStop> <code>deleteCheckpointOnStop</code> flag to control whether to delete the checkpoint directory on stop</li> </ul> <p><code>MicroBatchExecution</code> is created when:</p> <ul> <li> <p><code>StreamingQueryManager</code> is requested to <a href=../../StreamingQueryManager/#createQuery>create a streaming query</a> (when <code>DataStreamWriter</code> is requested to <a href=../../DataStreamWriter/#start>start an execution of the streaming query</a>) with the following:</p> </li> <li> <p>All <a href=#sink>sink</a>s</p> </li> <li>All <a href=#trigger>trigger</a>s but <a href=../../Trigger/#ContinuousTrigger>ContinuousTrigger</a></li> </ul> <p>Once created, <code>MicroBatchExecution</code> is requested to <a href=#runActivatedStream>run an activated streaming query</a>.</p> <h2 id=streaming-sources-registry><span id=sources> Streaming Sources Registry<a class=headerlink href=#streaming-sources-registry title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code><span class=n>sources</span><span class=k>:</span> <span class=kt>Seq</span><span class=o>[</span><span class=kt>SparkDataStream</span><span class=o>]</span>
</code></pre></div> <p><code>MicroBatchExecution</code> uses...FIXME</p> <p>Streaming sources and readers (of the <a href=../../logical-operators/StreamingExecutionRelation/ >StreamingExecutionRelations</a> of the <a href=#analyzedPlan>analyzed logical query plan</a> of the streaming query)</p> <p>Default: (empty)</p> <p><code>sources</code> is part of the <a href=../../monitoring/ProgressReporter/#sources>ProgressReporter</a> abstraction.</p> <ul> <li>Initialized when <code>MicroBatchExecution</code> is requested for the <a href=#logicalPlan>transformed logical query plan</a></li> </ul> <p>Used when:</p> <ul> <li> <p><a href=#populateStartOffsets>Populating start offsets</a> (for the <a href=../../StreamExecution/#availableOffsets>available</a> and <a href=../../StreamExecution/#committedOffsets>committed</a> offsets)</p> </li> <li> <p><a href=#constructNextBatch>Constructing or skipping next streaming micro-batch</a> (and persisting offsets to write-ahead log)</p> </li> </ul> <h2 id=triggerexecutor><span id=triggerExecutor> TriggerExecutor<a class=headerlink href=#triggerexecutor title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code><span class=n>triggerExecutor</span><span class=k>:</span> <span class=kt>TriggerExecutor</span>
</code></pre></div> <p><code>MicroBatchExecution</code> uses a <a href=../../TriggerExecutor/ >TriggerExecutor</a> that is how micro-batches are executed at regular intervals.</p> <p><code>triggerExecutor</code> is initialized based on the given <a href=#trigger>Trigger</a> (given when creating the <code>MicroBatchExecution</code>):</p> <ul> <li> <p><a href=../../TriggerExecutor/ >ProcessingTimeExecutor</a> for <a href=../../Trigger/#ProcessingTime>Trigger.ProcessingTime</a></p> </li> <li> <p><a href=../../TriggerExecutor/ >OneTimeExecutor</a> for <a href=../../Trigger/#OneTimeTrigger>OneTimeTrigger</a> (aka <a href=../../Trigger/#Once>Trigger.Once</a> trigger)</p> </li> </ul> <p><code>triggerExecutor</code> throws an <code>IllegalStateException</code> when the <a href=#trigger>Trigger</a> is not one of the <a href=../../Trigger/#available-implementations>built-in implementations</a>.</p> <div class=highlight><pre><span></span><code>Unknown type of trigger: [trigger]
</code></pre></div> <p><code>triggerExecutor</code> is used when:</p> <ul> <li><code>StreamExecution</code> is requested to <a href=#runActivatedStream>run an activated streaming query</a> (at regular intervals)</li> </ul> <h2 id=running-activated-streaming-query><span id=runActivatedStream> Running Activated Streaming Query<a class=headerlink href=#running-activated-streaming-query title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code><span class=n>runActivatedStream</span><span class=o>(</span>
  <span class=n>sparkSessionForStream</span><span class=k>:</span> <span class=kt>SparkSession</span><span class=o>)</span><span class=k>:</span> <span class=kt>Unit</span>
</code></pre></div> <p><code>runActivatedStream</code> simply requests the <a href=#triggerExecutor>TriggerExecutor</a> to execute micro-batches using the <a href=#batchRunner>batch runner</a> (until <code>MicroBatchExecution</code> is <a href=../../StreamExecution/#isActive>terminated</a> due to a query stop or a failure).</p> <p><code>runActivatedStream</code> is part of <a href=../../StreamExecution/#runActivatedStream>StreamExecution</a> abstraction.</p> <h3 id=triggerexecutors-batch-runner><span id=batchRunner><span id=batch-runner> TriggerExecutor's Batch Runner<a class=headerlink href=#triggerexecutors-batch-runner title="Permanent link">&para;</a></h3> <p>The batch runner (of the <a href=#triggerExecutor>TriggerExecutor</a>) is executed as long as the <code>MicroBatchExecution</code> is <a href=../../StreamExecution/#isActive>active</a>.</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p><em>trigger</em> and <em>batch</em> are considered equivalent and used interchangeably.</p> </div> <p><span id=runActivatedStream-startTrigger> The batch runner <a href=../../monitoring/ProgressReporter/#startTrigger>initializes query progress for the new trigger</a> (aka <em>startTrigger</em>).</p> <p><span id=runActivatedStream-triggerExecution><span id=runActivatedStream-triggerExecution-populateStartOffsets> The batch runner starts <em>triggerExecution</em> <a href=../../monitoring/ProgressReporter/#reportTimeTaken>execution phase</a> that is made up of the following steps:</p> <ol> <li> <p><a href=#populateStartOffsets>Populating start offsets from checkpoint</a> before the first "zero" batch (at every start or restart)</p> </li> <li> <p><a href=#constructNextBatch>Constructing or skipping the next streaming micro-batch</a></p> </li> <li> <p><a href=#runBatch>Running the streaming micro-batch</a></p> </li> </ol> <p>At the start or restart (<em>resume</em>) of a streaming query (when the <a href=#currentBatchId>current batch ID</a> is uninitialized and <code>-1</code>), the batch runner <a href=#populateStartOffsets>populates start offsets from checkpoint</a> and then prints out the following INFO message to the logs (using the <a href=../../StreamExecution/#committedOffsets>committedOffsets</a> internal registry):</p> <div class=highlight><pre><span></span><code>Stream started from [committedOffsets]
</code></pre></div> <p>The batch runner sets the human-readable description for any Spark job submitted (that streaming sources may submit to get new data) as the <a href=../../StreamExecution/#getBatchDescriptionString>batch description</a>.</p> <p><span id=runActivatedStream-triggerExecution-isCurrentBatchConstructed> The batch runner <a href=#constructNextBatch>constructs the next streaming micro-batch</a> (when the <a href=#isCurrentBatchConstructed>isCurrentBatchConstructed</a> internal flag is off).</p> <p>The batch runner <a href=#recordTriggerOffsets>records trigger offsets</a> (with the <a href=../../StreamExecution/#committedOffsets>committed</a> and <a href=../../StreamExecution/#availableOffsets>available</a> offsets).</p> <p>The batch runner updates the <a href=../../monitoring/ProgressReporter/#currentStatus>current StreamingQueryStatus</a> with the <a href=#isNewDataAvailable>isNewDataAvailable</a> for <a href=../../monitoring/StreamingQueryStatus/#isDataAvailable>isDataAvailable</a> property.</p> <p><span id=runActivatedStream-triggerExecution-runBatch> With the <a href=#isCurrentBatchConstructed>isCurrentBatchConstructed</a> flag enabled, the batch runner <a href=../../monitoring/ProgressReporter/#updateStatusMessage>updates the status message</a> to one of the following (per <a href=#isNewDataAvailable>isNewDataAvailable</a>) and <a href=#runBatch>runs the streaming micro-batch</a>.</p> <div class=highlight><pre><span></span><code>Processing new data
</code></pre></div> <div class=highlight><pre><span></span><code>No new data but cleaning up state
</code></pre></div> <p>With the <a href=#isCurrentBatchConstructed>isCurrentBatchConstructed</a> flag disabled (<code>false</code>), the batch runner simply <a href=../../monitoring/ProgressReporter/#updateStatusMessage>updates the status message</a> to the following:</p> <div class=highlight><pre><span></span><code>Waiting for data to arrive
</code></pre></div> <p>[[runActivatedStream-triggerExecution-finishTrigger]] The batch runner <a href=../../monitoring/ProgressReporter/#finishTrigger>finalizes query progress for the trigger</a> (with a flag that indicates whether the current batch had new data).</p> <p>With the <a href=#isCurrentBatchConstructed>isCurrentBatchConstructed</a> flag enabled (<code>true</code>), the batch runner increments the <a href=#currentBatchId>currentBatchId</a> and turns the <a href=#isCurrentBatchConstructed>isCurrentBatchConstructed</a> flag off (<code>false</code>).</p> <p>With the <a href=#isCurrentBatchConstructed>isCurrentBatchConstructed</a> flag disabled (<code>false</code>), the batch runner simply sleeps (as long as configured using the <a href=../../StreamExecution/#pollingDelayMs>spark.sql.streaming.pollingDelay</a> configuration property).</p> <p>In the end, the batch runner <a href=../../monitoring/ProgressReporter/#updateStatusMessage>updates the status message</a> to the following status and returns whether the <code>MicroBatchExecution</code> is <a href=../../StreamExecution/#isActive>active</a> or not.</p> <div class=highlight><pre><span></span><code>Waiting for next trigger
</code></pre></div> <h2 id=populating-start-offsets-from-checkpoint-resuming-from-checkpoint><span id=populateStartOffsets> Populating Start Offsets From Checkpoint (Resuming from Checkpoint)<a class=headerlink href=#populating-start-offsets-from-checkpoint-resuming-from-checkpoint title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code><span class=n>populateStartOffsets</span><span class=o>(</span>
  <span class=n>sparkSessionToRunBatches</span><span class=k>:</span> <span class=kt>SparkSession</span><span class=o>)</span><span class=k>:</span> <span class=kt>Unit</span>
</code></pre></div> <p><code>populateStartOffsets</code> requests the <a href=../../StreamExecution/#offsetLog>Offset Write-Ahead Log</a> for the <a href=../../HDFSMetadataLog/#getLatest>latest committed batch id with metadata</a> (i.e. <a href=../../OffsetSeq/ >OffsetSeq</a>).</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p>The batch id could not be available in the write-ahead log when a streaming query started with a new log or no batch was persisted (<em>added</em>) to the log before.</p> </div> <p><code>populateStartOffsets</code> branches off based on whether the latest committed batch was <a href=#populateStartOffsets-getLatest-available>available</a> or <a href=#populateStartOffsets-getLatest-not-available>not</a>.</p> <p><code>populateStartOffsets</code> is used when <code>MicroBatchExecution</code> is requested to <a href=#runActivatedStream>run an activated streaming query</a> (<a href=#runActivatedStream-triggerExecution-populateStartOffsets>before the first "zero" micro-batch</a>).</p> <h3 id=latest-committed-batch-available><span id=populateStartOffsets-getLatest-available> Latest Committed Batch Available<a class=headerlink href=#latest-committed-batch-available title="Permanent link">&para;</a></h3> <p>When the latest committed batch id with the metadata was available in the <a href=../../StreamExecution/#offsetLog>Offset Write-Ahead Log</a>, <code>populateStartOffsets</code> (re)initializes the internal state as follows:</p> <ul> <li> <p>Sets the <a href=../../StreamExecution/#currentBatchId>current batch ID</a> to the latest committed batch ID found</p> </li> <li> <p>Turns the <a href=#isCurrentBatchConstructed>isCurrentBatchConstructed</a> internal flag on (<code>true</code>)</p> </li> <li> <p>Sets the <a href=#availableOffsets>available offsets</a> to the offsets (from the metadata)</p> </li> </ul> <p>When the latest batch ID found is greater than <code>0</code>, <code>populateStartOffsets</code> requests the <a href=../../StreamExecution/#offsetLog>Offset Write-Ahead Log</a> for the <a href=../../HDFSMetadataLog/#get>second latest batch ID with metadata</a> or throws an <code>IllegalStateException</code> if not found.</p> <div class=highlight><pre><span></span><code>batch [latestBatchId - 1] doesn&#39;t exist
</code></pre></div> <p><code>populateStartOffsets</code> sets the <a href=#committedOffsets>committed offsets</a> to the second latest committed offsets.</p> <p><span id=populateStartOffsets-getLatest-available-offsetSeqMetadata> <code>populateStartOffsets</code> updates the offset metadata.</p> <p>CAUTION: FIXME Describe me</p> <p><code>populateStartOffsets</code> requests the <a href=../../StreamExecution/#commitLog>Offset Commit Log</a> for the <a href=../../HDFSMetadataLog/#getLatest>latest committed batch id with metadata</a>.</p> <p>CAUTION: FIXME Describe me</p> <p>When the latest committed batch id with metadata was found which is exactly the latest batch ID (found in the <a href=../../StreamExecution/#commitLog>Offset Commit Log</a>), <code>populateStartOffsets</code>...FIXME</p> <p>When the latest committed batch id with metadata was found, but it is not exactly the second latest batch ID (found in the <a href=../../StreamExecution/#commitLog>Offset Commit Log</a>), <code>populateStartOffsets</code> prints out the following WARN message to the logs:</p> <div class=highlight><pre><span></span><code>Batch completion log latest batch id is [latestCommittedBatchId], which is not trailing batchid [latestBatchId] by one
</code></pre></div> <p>When no commit log present in the <a href=../../StreamExecution/#commitLog>Offset Commit Log</a>, <code>populateStartOffsets</code> prints out the following INFO message to the logs:</p> <div class=highlight><pre><span></span><code>no commit log present
</code></pre></div> <p>In the end, <code>populateStartOffsets</code> prints out the following DEBUG message to the logs:</p> <div class=highlight><pre><span></span><code>Resuming at batch [currentBatchId] with committed offsets [committedOffsets] and available offsets [availableOffsets]
</code></pre></div> <h3 id=no-latest-committed-batch><span id=populateStartOffsets-getLatest-not-available> No Latest Committed Batch<a class=headerlink href=#no-latest-committed-batch title="Permanent link">&para;</a></h3> <p>When the latest committed batch id with the metadata could not be found in the <a href=../../StreamExecution/#offsetLog>Offset Write-Ahead Log</a>, it is assumed that the streaming query is started for the very first time (or the <a href=../../StreamExecution/#checkpointRoot>checkpoint location</a> has changed).</p> <p><code>populateStartOffsets</code> prints out the following INFO message to the logs:</p> <div class=highlight><pre><span></span><code>Starting new streaming query.
</code></pre></div> <p>[[populateStartOffsets-currentBatchId-0]] <code>populateStartOffsets</code> sets the <a href=../../StreamExecution/#currentBatchId>current batch ID</a> to <code>0</code> and creates a new <a href=#watermarkTracker>WatermarkTracker</a>.</p> <h2 id=constructing-or-skipping-next-streaming-micro-batch><span id=constructNextBatch> Constructing Or Skipping Next Streaming Micro-Batch<a class=headerlink href=#constructing-or-skipping-next-streaming-micro-batch title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code><span class=n>constructNextBatch</span><span class=o>(</span>
  <span class=n>noDataBatchesEnabled</span><span class=k>:</span> <span class=kt>Boolean</span><span class=o>)</span><span class=k>:</span> <span class=kt>Boolean</span>
</code></pre></div> <p><code>constructNextBatch</code> is used when <code>MicroBatchExecution</code> is requested to <a href=#runActivatedStream>run the activated streaming query</a>.</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p><code>constructNextBatch</code> is only executed when the <a href=#isCurrentBatchConstructed>isCurrentBatchConstructed</a> internal flag is enabled (<code>true</code>).</p> </div> <p><code>constructNextBatch</code> performs the following steps:</p> <ol> <li> <p><a href=#constructNextBatch-latestOffsets>Requesting the latest offsets from every streaming source</a> (of the streaming query)</p> </li> <li> <p><a href=#constructNextBatch-availableOffsets>Updating availableOffsets StreamProgress with the latest available offsets</a></p> </li> <li> <p><a href=#constructNextBatch-offsetSeqMetadata>Updating batch metadata with the current event-time watermark and batch timestamp</a></p> </li> <li> <p><a href=#constructNextBatch-shouldConstructNextBatch>Checking whether to construct the next micro-batch or not (skip it)</a></p> </li> </ol> <p>In the end, <code>constructNextBatch</code> returns <a href=#constructNextBatch-shouldConstructNextBatch>whether the next streaming micro-batch was constructed or skipped</a>.</p> <h3 id=requesting-latest-offsets-from-streaming-sources-getoffset-setoffsetrange-and-getendoffset-phases><span id=constructNextBatch-latestOffsets> Requesting Latest Offsets from Streaming Sources (getOffset, setOffsetRange and getEndOffset Phases)<a class=headerlink href=#requesting-latest-offsets-from-streaming-sources-getoffset-setoffsetrange-and-getendoffset-phases title="Permanent link">&para;</a></h3> <p><code>constructNextBatch</code> firstly requests every <a href=../../StreamExecution/#uniqueSources>streaming source</a> for the latest offsets.</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p><code>constructNextBatch</code> checks out the latest offset in every streaming data source sequentially, i.e. one data source at a time.</p> </div> <p><img alt="MicroBatchExecution's Getting Offsets From Streaming Sources" src=../../images/MicroBatchExecution-constructNextBatch.png></p> <p>For every <a href=../../Source/ >streaming source</a> (Data Source API V1), <code>constructNextBatch</code> <a href=../../monitoring/ProgressReporter/#updateStatusMessage>updates the status message</a> to the following:</p> <div class=highlight><pre><span></span><code>Getting offsets from [source]
</code></pre></div> <h3 id=getoffset-phase><span id=constructNextBatch-getOffset> getOffset Phase<a class=headerlink href=#getoffset-phase title="Permanent link">&para;</a></h3> <p>In <strong>getOffset</strong> <a href=../../monitoring/ProgressReporter/#reportTimeTaken>time-tracking section</a>, <code>constructNextBatch</code> requests the <code>Source</code> for the <a href=#getOffset>latest offset</a>.</p> <p>For every <a href=../MicroBatchReader/ >MicroBatchReader</a> (Data Source API V2), <code>constructNextBatch</code> <a href=../../monitoring/ProgressReporter/#updateStatusMessage>updates the status message</a> to the following:</p> <div class=highlight><pre><span></span><code>Getting offsets from [source]
</code></pre></div> <h3 id=setoffsetrange-phase><span id=constructNextBatch-setOffsetRange> setOffsetRange Phase<a class=headerlink href=#setoffsetrange-phase title="Permanent link">&para;</a></h3> <p>In <strong>setOffsetRange</strong> <a href=../../monitoring/ProgressReporter/#reportTimeTaken>time-tracking section</a>, <code>constructNextBatch</code> finds the available offsets of the source (in the <a href=#availableOffsets>available offset</a> internal registry) and, if found, requests the <code>MicroBatchReader</code> to <a href=../MicroBatchReader/#deserializeOffset>deserialize the offset</a> (from <a href=../../Offset/#json>JSON format</a>). <code>constructNextBatch</code> requests the <code>MicroBatchReader</code> to <a href=../MicroBatchReader/#setOffsetRange>set the desired offset range</a>.</p> <h3 id=getendoffset-phase><span id=constructNextBatch-getEndOffset> getEndOffset Phase<a class=headerlink href=#getendoffset-phase title="Permanent link">&para;</a></h3> <p>In <strong>getEndOffset</strong> <a href=../../monitoring/ProgressReporter/#reportTimeTaken>time-tracking section</a>, <code>constructNextBatch</code> requests the <code>MicroBatchReader</code> for the <a href=../MicroBatchReader/#getEndOffset>end offset</a>.</p> <h3 id=updating-availableoffsets-streamprogress-with-latest-available-offsets><span id=constructNextBatch-availableOffsets> Updating availableOffsets StreamProgress with Latest Available Offsets<a class=headerlink href=#updating-availableoffsets-streamprogress-with-latest-available-offsets title="Permanent link">&para;</a></h3> <p><code>constructNextBatch</code> updates the <a href=../../StreamExecution/#availableOffsets>availableOffsets StreamProgress</a> with the latest reported offsets.</p> <h3 id=updating-batch-metadata-with-current-event-time-watermark-and-batch-timestamp><span id=constructNextBatch-offsetSeqMetadata> Updating Batch Metadata with Current Event-Time Watermark and Batch Timestamp<a class=headerlink href=#updating-batch-metadata-with-current-event-time-watermark-and-batch-timestamp title="Permanent link">&para;</a></h3> <p><code>constructNextBatch</code> updates the <a href=../../StreamExecution/#offsetSeqMetadata>batch metadata</a> with the current <a href=../../WatermarkTracker/#currentWatermark>event-time watermark</a> (from the <a href=#watermarkTracker>WatermarkTracker</a>) and the batch timestamp.</p> <h3 id=checking-whether-to-construct-next-micro-batch-or-not-skip-it><span id=constructNextBatch-shouldConstructNextBatch> Checking Whether to Construct Next Micro-Batch or Not (Skip It)<a class=headerlink href=#checking-whether-to-construct-next-micro-batch-or-not-skip-it title="Permanent link">&para;</a></h3> <p><code>constructNextBatch</code> checks whether or not the next streaming micro-batch should be constructed (<code>lastExecutionRequiresAnotherBatch</code>).</p> <p><code>constructNextBatch</code> uses the <a href=../../StreamExecution/#lastExecution>last IncrementalExecution</a> if the <a href=../../IncrementalExecution/#shouldRunAnotherBatch>last execution requires another micro-batch</a> (using the <a href=../../StreamExecution/#offsetSeqMetadata>batch metadata</a>) and the given <code>noDataBatchesEnabled</code> flag is enabled (<code>true</code>).</p> <p><code>constructNextBatch</code> also <a href=#isNewDataAvailable>checks out whether new data is available (based on available and committed offsets)</a>.</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p><code>shouldConstructNextBatch</code> local flag is enabled (<code>true</code>) when <a href=#isNewDataAvailable>there is new data available (based on offsets)</a> or the <a href=../../IncrementalExecution/#shouldRunAnotherBatch>last execution requires another micro-batch</a> (and the given <code>noDataBatchesEnabled</code> flag is enabled).</p> </div> <p><code>constructNextBatch</code> prints out the following TRACE message to the logs:</p> <div class=highlight><pre><span></span><code>noDataBatchesEnabled = [noDataBatchesEnabled], lastExecutionRequiresAnotherBatch = [lastExecutionRequiresAnotherBatch], isNewDataAvailable = [isNewDataAvailable], shouldConstructNextBatch = [shouldConstructNextBatch]
</code></pre></div> <p><code>constructNextBatch</code> branches off per whether to <a href=#constructNextBatch-shouldConstructNextBatch-enabled>constructs</a> or <a href=#constructNextBatch-shouldConstructNextBatch-disabled>skip</a> the next batch (per <code>shouldConstructNextBatch</code> flag in the above TRACE message).</p> <h3 id=constructing-next-micro-batch><span id=constructNextBatch-shouldConstructNextBatch-enabled> Constructing Next Micro-Batch<a class=headerlink href=#constructing-next-micro-batch title="Permanent link">&para;</a></h3> <p>With the <a href=#constructNextBatch-shouldConstructNextBatch>shouldConstructNextBatch</a> flag enabled (<code>true</code>), <code>constructNextBatch</code> <a href=../../monitoring/ProgressReporter/#updateStatusMessage>updates the status message</a> to the following:</p> <div class=highlight><pre><span></span><code>Writing offsets to log
</code></pre></div> <p>[[constructNextBatch-walCommit]] In <em>walCommit</em> <a href=../../monitoring/ProgressReporter/#reportTimeTaken>time-tracking section</a>, <code>constructNextBatch</code> requests the <a href=../../StreamExecution/#availableOffsets>availableOffsets StreamProgress</a> to <a href=../../StreamProgress/#toOffsetSeq>convert to OffsetSeq</a> (with the <a href=#sources>BaseStreamingSources</a> and the <a href=../../StreamExecution/#offsetSeqMetadata>current batch metadata (event-time watermark and timestamp)</a>) that is in turn <a href=../../HDFSMetadataLog/#add>added</a> to the <a href=../../StreamExecution/#offsetLog>write-ahead log</a> for the <a href=../../StreamExecution/#currentBatchId>current batch ID</a>.</p> <p><code>constructNextBatch</code> prints out the following INFO message to the logs:</p> <div class=highlight><pre><span></span><code>Committed offsets for batch [currentBatchId]. Metadata [offsetSeqMetadata]
</code></pre></div> <details class=fixme><summary>Fixme</summary><p>(<code>if (currentBatchId != 0) ...</code>)</p> </details> <details class=fixme><summary>Fixme</summary><p>(<code>if (minLogEntriesToMaintain &lt; currentBatchId) ...</code>)</p> </details> <p><code>constructNextBatch</code> turns the <a href=../../StreamExecution/#noNewData>noNewData</a> internal flag off (<code>false</code>).</p> <p>In case of a failure while <a href=../../HDFSMetadataLog/#add>adding the available offsets</a> to the <a href=../../StreamExecution/#offsetLog>write-ahead log</a>, <code>constructNextBatch</code> throws an <code>AssertionError</code>:</p> <div class=highlight><pre><span></span><code>Concurrent update to the log. Multiple streaming jobs detected for [currentBatchId]
</code></pre></div> <h3 id=skipping-next-micro-batch><span id=constructNextBatch-shouldConstructNextBatch-disabled> Skipping Next Micro-Batch<a class=headerlink href=#skipping-next-micro-batch title="Permanent link">&para;</a></h3> <p>With the <a href=#constructNextBatch-shouldConstructNextBatch>shouldConstructNextBatch</a> flag disabled (<code>false</code>), <code>constructNextBatch</code> turns the <a href=../../StreamExecution/#noNewData>noNewData</a> flag on (<code>true</code>) and wakes up (<em>notifies</em>) all threads waiting for the <a href=../../StreamExecution/#awaitProgressLockCondition>awaitProgressLockCondition</a> lock.</p> <h2 id=running-single-streaming-micro-batch><span id=runBatch> Running Single Streaming Micro-Batch<a class=headerlink href=#running-single-streaming-micro-batch title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code><span class=n>runBatch</span><span class=o>(</span>
  <span class=n>sparkSessionToRunBatch</span><span class=k>:</span> <span class=kt>SparkSession</span><span class=o>)</span><span class=k>:</span> <span class=kt>Unit</span>
</code></pre></div> <p><code>runBatch</code> prints out the following DEBUG message to the logs (with the <a href=../../StreamExecution/#currentBatchId>current batch ID</a>):</p> <div class=highlight><pre><span></span><code>Running batch [currentBatchId]
</code></pre></div> <p><code>runBatch</code> then performs the following steps (aka <em>phases</em>):</p> <ol> <li><a href=#runBatch-getBatch>getBatch Phase -- Creating Logical Query Plans For Unprocessed Data From Sources and MicroBatchReaders</a></li> <li><a href=#runBatch-newBatchesPlan>Transforming Logical Plan to Include Sources and MicroBatchReaders with New Data</a></li> <li><a href=#runBatch-newAttributePlan>Transforming CurrentTimestamp and CurrentDate Expressions (Per Batch Metadata)</a></li> <li><a href=#runBatch-triggerLogicalPlan>Adapting Transformed Logical Plan to Sink with StreamWriteSupport</a></li> <li><a href=#runBatch-setLocalProperty>Setting Local Properties</a></li> <li><a href=#runBatch-queryPlanning>queryPlanning Phase -- Creating and Preparing IncrementalExecution for Execution</a></li> <li><a href=#runBatch-nextBatch>nextBatch Phase -- Creating DataFrame (with IncrementalExecution for New Data)</a></li> <li><a href=#runBatch-addBatch>addBatch Phase -- Adding DataFrame With New Data to Sink</a></li> <li><a href=#runBatch-updateWatermark-commitLog>Updating Watermark and Committing Offsets to Offset Commit Log</a></li> </ol> <p>In the end, <code>runBatch</code> prints out the following DEBUG message to the logs (with the <a href=../../StreamExecution/#currentBatchId>current batch ID</a>):</p> <div class=highlight><pre><span></span><code>Completed batch [currentBatchId]
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Note</p> <p><code>runBatch</code> is used exclusively when <code>MicroBatchExecution</code> is requested to <a href=#runActivatedStream>run an activated streaming query</a> (and there is new data to process).</p> </div> <h3 id=getbatch-phase-creating-logical-query-plans-for-unprocessed-data-from-sources-and-microbatchreaders><span id=runBatch-getBatch> getBatch Phase -- Creating Logical Query Plans For Unprocessed Data From Sources and MicroBatchReaders<a class=headerlink href=#getbatch-phase-creating-logical-query-plans-for-unprocessed-data-from-sources-and-microbatchreaders title="Permanent link">&para;</a></h3> <p>In <em>getBatch</em> <a href=../../monitoring/ProgressReporter/#reportTimeTaken>time-tracking section</a>, <code>runBatch</code> goes over the <a href=../../StreamExecution/#availableOffsets>available offsets</a> and processes every <a href=#runBatch-getBatch-Source>Source</a> and <a href=#runBatch-getBatch-MicroBatchReader>MicroBatchReader</a> (associated with the available offsets) to create logical query plans (<code>newData</code>) for data processing (per offset ranges).</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p><code>runBatch</code> requests sources and readers for data per offset range sequentially, one by one.</p> </div> <p><img alt="StreamExecution's Running Single Streaming Batch (getBatch Phase)" src=../../images/StreamExecution-runBatch-getBatch.png></p> <h3 id=getbatch-phase-and-sources><span id=runBatch-getBatch-Source> getBatch Phase and Sources<a class=headerlink href=#getbatch-phase-and-sources title="Permanent link">&para;</a></h3> <p>For a <a href=../../Source/ >Source</a> (with the available <a href=../../Offset/ >offset</a>s different from the <a href=../../StreamExecution/#committedOffsets>committedOffsets</a> registry), <code>runBatch</code> does the following:</p> <ul> <li> <p>Requests the <a href=../../StreamExecution/#committedOffsets>committedOffsets</a> for the committed offsets for the <code>Source</code> (if available)</p> </li> <li> <p>Requests the <code>Source</code> for a <a href=../../Source/#getBatch>dataframe for the offset range</a> (the current and available offsets)</p> </li> </ul> <p><code>runBatch</code> prints out the following DEBUG message to the logs.</p> <div class=highlight><pre><span></span><code>Retrieving data from [source]: [current] -&gt; [available]
</code></pre></div> <p>In the end, <code>runBatch</code> returns the <code>Source</code> and the logical plan of the streaming dataset (for the offset range).</p> <p>In case the <code>Source</code> returns a dataframe that is not streaming, <code>runBatch</code> throws an <code>AssertionError</code>:</p> <div class=highlight><pre><span></span><code>DataFrame returned by getBatch from [source] did not have isStreaming=true\n[logicalQueryPlan]
</code></pre></div> <h3 id=getbatch-phase-and-microbatchreaders><span id=runBatch-getBatch-MicroBatchReader> getBatch Phase and MicroBatchReaders<a class=headerlink href=#getbatch-phase-and-microbatchreaders title="Permanent link">&para;</a></h3> <p>For a <a href=../MicroBatchReader/ >MicroBatchReader</a> (with the available <a href=../../Offset/ >offset</a>s different from the <a href=../../StreamExecution/#committedOffsets>committedOffsets</a> registry), <code>runBatch</code> does the following:</p> <ul> <li> <p>Requests the <a href=../../StreamExecution/#committedOffsets>committedOffsets</a> for the committed offsets for the <code>MicroBatchReader</code> (if available)</p> </li> <li> <p>Requests the <code>MicroBatchReader</code> to <a href=../MicroBatchReader/#deserializeOffset>deserialize the committed offsets</a> (if available)</p> </li> <li> <p>Requests the <code>MicroBatchReader</code> to <a href=../MicroBatchReader/#deserializeOffset>deserialize the available offsets</a> (only for <a href=../../Offset/#SerializedOffset>SerializedOffset</a>s)</p> </li> <li> <p>Requests the <code>MicroBatchReader</code> to <a href=../MicroBatchReader/#setOffsetRange>set the offset range</a> (the current and available offsets)</p> </li> </ul> <p><code>runBatch</code> prints out the following DEBUG message to the logs.</p> <div class=highlight><pre><span></span><code>Retrieving data from [reader]: [current] -&gt; [availableV2]
</code></pre></div> <p><code>runBatch</code> looks up the <code>DataSourceV2</code> and the options for the <code>MicroBatchReader</code> (in the <a href=#readerToDataSourceMap>readerToDataSourceMap</a> internal registry).</p> <p>In the end, <code>runBatch</code> requests the <code>MicroBatchReader</code> for the <a href=../MicroBatchReader/#readSchema>read schema</a> and creates a <a href=../../logical-operators/StreamingDataSourceV2Relation/ >StreamingDataSourceV2Relation</a> logical operator (with the read schema, the <code>DataSourceV2</code>, options, and the <code>MicroBatchReader</code>).</p> <h3 id=transforming-logical-plan-to-include-sources-and-microbatchreaders-with-new-data><span id=runBatch-newBatchesPlan> Transforming Logical Plan to Include Sources and MicroBatchReaders with New Data<a class=headerlink href=#transforming-logical-plan-to-include-sources-and-microbatchreaders-with-new-data title="Permanent link">&para;</a></h3> <p><img alt="StreamExecution's Running Single Streaming Batch (and Transforming Logical Plan for New Data)" src=../../images/StreamExecution-runBatch-newBatchesPlan.png></p> <p><code>runBatch</code> transforms the <a href=#logicalPlan>analyzed logical plan</a> to include <a href=#runBatch-getBatch>Sources and MicroBatchReaders with new data</a> (<code>newBatchesPlan</code> with logical plans to process data that has arrived since the last batch).</p> <p>For every <a href=../../logical-operators/StreamingExecutionRelation/ >StreamingExecutionRelation</a>, <code>runBatch</code> tries to find the corresponding logical plan for processing new data.</p> <p>If the logical plan is found, <code>runBatch</code> makes the plan a child operator of <code>Project</code> (with <code>Aliases</code>) logical operator and replaces the <code>StreamingExecutionRelation</code>.</p> <p>Otherwise, if not found, <code>runBatch</code> simply creates an empty streaming <code>LocalRelation</code> (for scanning data from an empty local collection).</p> <p>In case the number of columns in dataframes with new data and <code>StreamingExecutionRelation</code>'s do not match, <code>runBatch</code> throws an <code>AssertionError</code>:</p> <div class=highlight><pre><span></span><code>Invalid batch: [output] != [dataPlan.output]
</code></pre></div> <h3 id=transforming-currenttimestamp-and-currentdate-expressions-per-batch-metadata><span id=runBatch-newAttributePlan> Transforming CurrentTimestamp and CurrentDate Expressions (Per Batch Metadata)<a class=headerlink href=#transforming-currenttimestamp-and-currentdate-expressions-per-batch-metadata title="Permanent link">&para;</a></h3> <p><code>runBatch</code> replaces all <code>CurrentTimestamp</code> and <code>CurrentDate</code> expressions in the <a href=#runBatch-newBatchesPlan>transformed logical plan (with new data)</a> with the <a href=../../OffsetSeqMetadata/#batchTimestampMs>current batch timestamp</a> (based on the <a href=../../StreamExecution/#offsetSeqMetadata>batch metadata</a>).</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p><code>CurrentTimestamp</code> and <code>CurrentDate</code> expressions correspond to <code>current_timestamp</code> and <code>current_date</code> standard function, respectively.</p> </div> <h3 id=adapting-transformed-logical-plan-to-sink-with-streamwritesupport><span id=runBatch-triggerLogicalPlan> Adapting Transformed Logical Plan to Sink with StreamWriteSupport<a class=headerlink href=#adapting-transformed-logical-plan-to-sink-with-streamwritesupport title="Permanent link">&para;</a></h3> <p><code>runBatch</code>...FIXME</p> <p>For a <a href=../../Sink/ >Sink</a> (Data Source API V1), <code>runBatch</code> changes nothing.</p> <p>For any other <a href=#sink>BaseStreamingSink</a> type, <code>runBatch</code> simply throws an <code>IllegalArgumentException</code>:</p> <div class=highlight><pre><span></span><code>unknown sink type for [sink]
</code></pre></div> <h3 id=setting-local-properties><span id=runBatch-setLocalProperty> Setting Local Properties<a class=headerlink href=#setting-local-properties title="Permanent link">&para;</a></h3> <p><code>runBatch</code> sets the local properties.</p> <table> <thead> <tr> <th>Local Property</th> <th>Value</th> </tr> </thead> <tbody> <tr> <td><a href=#BATCH_ID_KEY>streaming.sql.batchId</a></td> <td><a href=../../StreamExecution/#currentBatchId>currentBatchId</a></td> </tr> <tr> <td><a href=../../StreamExecution/#IS_CONTINUOUS_PROCESSING>__is_continuous_processing</a></td> <td><code>false</code></td> </tr> </tbody> </table> <h3 id=queryplanning-phase-creating-and-preparing-incrementalexecution-for-execution><span id=runBatch-queryPlanning> queryPlanning Phase -- Creating and Preparing IncrementalExecution for Execution<a class=headerlink href=#queryplanning-phase-creating-and-preparing-incrementalexecution-for-execution title="Permanent link">&para;</a></h3> <p><img alt="StreamExecution's Query Planning (queryPlanning Phase)" src=../../images/StreamExecution-runBatch-queryPlanning.png></p> <p>In <em>queryPlanning</em> <a href=../../monitoring/ProgressReporter/#reportTimeTaken>time-tracking section</a>, <code>runBatch</code> creates a new <a href=../../StreamExecution/#lastExecution>IncrementalExecution</a> with the following:</p> <ul> <li> <p><a href=#runBatch-triggerLogicalPlan>Transformed logical plan</a></p> </li> <li> <p><a href=#outputMode>Output mode</a></p> </li> <li> <p><code>state</code> <a href=#checkpointFile>checkpoint directory</a></p> </li> <li> <p><a href=../../StreamExecution/#runId>Run ID</a></p> </li> <li> <p><a href=../../StreamExecution/#currentBatchId>Batch ID</a></p> </li> <li> <p><a href=../../StreamExecution/#offsetSeqMetadata>Batch Metadata (Event-Time Watermark and Timestamp)</a></p> </li> </ul> <p>In the end (of the <code>queryPlanning</code> phase), <code>runBatch</code> requests the <code>IncrementalExecution</code> to prepare the transformed logical plan for execution (i.e. execute the <code>executedPlan</code> query execution phase).</p> <div class="admonition tip"> <p class=admonition-title>Tip</p> <p>Read up on the <code>executedPlan</code> query execution phase in <a href=https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-QueryExecution.html[The>https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-QueryExecution.html[The</a> Internals of Spark SQL].</p> </div> <h3 id=nextbatch-phase-creating-dataframe-with-incrementalexecution-for-new-data><span id=runBatch-nextBatch> nextBatch Phase &mdash; Creating DataFrame (with IncrementalExecution for New Data)<a class=headerlink href=#nextbatch-phase-creating-dataframe-with-incrementalexecution-for-new-data title="Permanent link">&para;</a></h3> <p><img alt="StreamExecution Creates DataFrame with New Data" src=../../images/StreamExecution-runBatch-nextBatch.png></p> <p><code>runBatch</code> creates a new <code>DataFrame</code> with the new <a href=#runBatch-queryPlanning>IncrementalExecution</a>.</p> <p>The <code>DataFrame</code> represents the result of executing the current micro-batch of the streaming query.</p> <h3 id=addbatch-phase-adding-dataframe-with-new-data-to-sink><span id=runBatch-addBatch> addBatch Phase &mdash; Adding DataFrame With New Data to Sink<a class=headerlink href=#addbatch-phase-adding-dataframe-with-new-data-to-sink title="Permanent link">&para;</a></h3> <p><img alt="StreamExecution Adds DataFrame With New Data to Sink" src=../../images/StreamExecution-runBatch-addBatch.png></p> <p>In <strong>addBatch</strong> <a href=../../monitoring/ProgressReporter/#reportTimeTaken>time-tracking section</a>, <code>runBatch</code> adds the <code>DataFrame</code> with new data to the <a href=#sink>BaseStreamingSink</a>.</p> <p>For a <a href=../../Sink/ >Sink</a> (Data Source API V1), <code>runBatch</code> simply requests the <code>Sink</code> to <a href=../../Sink/#addBatch>add the DataFrame</a> (with the <a href=../../StreamExecution/#currentBatchId>batch ID</a>).</p> <p><code>runBatch</code> uses <code>SQLExecution.withNewExecutionId</code> to execute and track all the Spark jobs under one execution id (so it is reported as one single multi-job execution, e.g. in web UI).</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p><code>SQLExecution.withNewExecutionId</code> posts a <code>SparkListenerSQLExecutionStart</code> event before execution and a <code>SparkListenerSQLExecutionEnd</code> event right afterwards.</p> </div> <div class="admonition tip"> <p class=admonition-title>Tip</p> <p>Register <code>SparkListener</code> to get notified about the SQL execution events (<code>SparkListenerSQLExecutionStart</code> and <code>SparkListenerSQLExecutionEnd</code>).</p> </div> <h3 id=updating-watermark-and-committing-offsets-to-offset-commit-log><span id=runBatch-updateWatermark-commitLog> Updating Watermark and Committing Offsets to Offset Commit Log<a class=headerlink href=#updating-watermark-and-committing-offsets-to-offset-commit-log title="Permanent link">&para;</a></h3> <p><code>runBatch</code> requests the <a href=#watermarkTracker>WatermarkTracker</a> to <a href=../../WatermarkTracker/#updateWatermark>update event-time watermark</a> (with the <code>executedPlan</code> of the <a href=#runBatch-queryPlanning>IncrementalExecution</a>).</p> <p><code>runBatch</code> requests the <a href=../../StreamExecution/#commitLog>Offset Commit Log</a> to <a href=../../HDFSMetadataLog/#add>persisting metadata of the streaming micro-batch</a> (with the current <a href=../../StreamExecution/#currentBatchId>batch ID</a> and <a href=../../WatermarkTracker/#currentWatermark>event-time watermark</a> of the <a href=#watermarkTracker>WatermarkTracker</a>).</p> <p>In the end, <code>runBatch</code> <a href=../../StreamProgress/#plusplus>adds</a> the <a href=../../StreamExecution/#availableOffsets>available offsets</a> to the <a href=../../StreamExecution/#committedOffsets>committed offsets</a> (and updates the <a href=../../Offset/ >offset</a>s of every source with new data in the current micro-batch).</p> <h2 id=stopping-stream-processing-execution-of-streaming-query><span id=stop> Stopping Stream Processing (Execution of Streaming Query)<a class=headerlink href=#stopping-stream-processing-execution-of-streaming-query title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code><span class=n>stop</span><span class=o>()</span><span class=k>:</span> <span class=kt>Unit</span>
</code></pre></div> <p><code>stop</code> sets the <a href=../../StreamExecution/#state>state</a> to <code>TERMINATED</code>.</p> <p>When the <a href=../../StreamExecution/#queryExecutionThread>stream execution thread</a> is alive, <code>stop</code> requests the current <code>SparkContext</code> to <code>cancelJobGroup</code> identified by the <a href=../../StreamExecution/#runId>runId</a> and waits for this thread to die. Just to make sure that there are no more streaming jobs, <code>stop</code> requests the current <code>SparkContext</code> to <code>cancelJobGroup</code> identified by the <a href=../../StreamExecution/#runId>runId</a> again.</p> <p>In the end, <code>stop</code> prints out the following INFO message to the logs:</p> <div class=highlight><pre><span></span><code>Query [prettyIdString] was stopped
</code></pre></div> <p><code>stop</code> is part of the <a href=../../StreamingQuery/#stop>StreamingQuery</a> abstraction.</p> <h2 id=checking-whether-new-data-is-available><span id=isNewDataAvailable> Checking Whether New Data Is Available<a class=headerlink href=#checking-whether-new-data-is-available title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code><span class=n>isNewDataAvailable</span><span class=k>:</span> <span class=kt>Boolean</span>
</code></pre></div> <p><code>isNewDataAvailable</code> checks whether there is a streaming source (in the <a href=#availableOffsets>available offsets</a>) for which <a href=#committedOffsets>committed offsets</a> are different from the available offsets or not available (committed) at all.</p> <p><code>isNewDataAvailable</code> is positive (<code>true</code>) when there is at least one such streaming source.</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p><code>isNewDataAvailable</code> is used when <code>MicroBatchExecution</code> is requested to <a href=#runActivatedStream>run an activated streaming query</a> and <a href=#constructNextBatch>construct the next streaming micro-batch</a>.</p> </div> <h2 id=analyzed-logical-plan><span id=logicalPlan> Analyzed Logical Plan<a class=headerlink href=#analyzed-logical-plan title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code><span class=n>logicalPlan</span><span class=k>:</span> <span class=kt>LogicalPlan</span>
</code></pre></div> <p><code>logicalPlan</code> is part of the <a href=../../StreamExecution/#logicalPlan>StreamExecution</a> abstraction.</p> <p><code>logicalPlan</code> resolves (<em>replaces</em>) <a href=../../logical-operators/StreamingRelation/ >StreamingRelation</a>, <a href=../../logical-operators/StreamingRelationV2/ >StreamingRelationV2</a> logical operators to <a href=../../logical-operators/StreamingExecutionRelation/ >StreamingExecutionRelation</a> logical operators. <code>logicalPlan</code> uses the transformed logical plan to set the <a href=../../StreamExecution/#uniqueSources>uniqueSources</a> and <a href=#sources>sources</a> internal registries to be the <a href=../../logical-operators/StreamingExecutionRelation/#source>BaseStreamingSources</a> of all the <code>StreamingExecutionRelations</code> unique and not, respectively.</p> <details class=note><summary>Lazy Value</summary></details> <p><code>logicalPlan</code> is a Scala <strong>lazy value</strong> to guarantee that the code to initialize it is executed once only (when accessed for the first time) and cached afterwards.</p> <p>Internally, <code>logicalPlan</code> transforms the <a href=#analyzedPlan>analyzed logical plan</a>.</p> <p>For every <a href=../../logical-operators/StreamingRelation/ >StreamingRelation</a> logical operator, <code>logicalPlan</code> tries to replace it with the <a href=../../logical-operators/StreamingExecutionRelation/ >StreamingExecutionRelation</a> that was used earlier for the same <code>StreamingRelation</code> (if used multiple times in the plan) or creates a new one. While creating a new <code>StreamingExecutionRelation</code>, <code>logicalPlan</code> requests the <code>DataSource</code> to <a href=../../DataSource/#createSource>create a streaming Source</a> with the metadata path as <code>sources/uniqueID</code> directory in the <a href=../../StreamExecution/#resolvedCheckpointRoot>checkpoint root directory</a>. <code>logicalPlan</code> prints out the following INFO message to the logs:</p> <div class=highlight><pre><span></span><code>Using Source [source] from DataSourceV1 named &#39;[sourceName]&#39; [dataSourceV1]
</code></pre></div> <p>For every <a href=../../logical-operators/StreamingRelationV2/ >StreamingRelationV2</a> logical operator with a <a href=../../MicroBatchStream/ >MicroBatchStream</a> data source (which is not on the list of <a href=../../configuration-properties/#spark.sql.streaming.disabledV2MicroBatchReaders>spark.sql.streaming.disabledV2MicroBatchReaders</a>), <code>logicalPlan</code> tries to replace it with the <a href=../../logical-operators/StreamingExecutionRelation/ >StreamingExecutionRelation</a> that was used earlier for the same <code>StreamingRelationV2</code> (if used multiple times in the plan) or creates a new one. While creating a new <code>StreamingExecutionRelation</code>, <code>logicalPlan</code> requests the <code>MicroBatchStream</code> to <a href=../../MicroBatchStream/#createMicroBatchReader>create a MicroBatchStream</a> with the metadata path as <code>sources/uniqueID</code> directory in the <a href=../../StreamExecution/#resolvedCheckpointRoot>checkpoint root directory</a>. <code>logicalPlan</code> prints out the following INFO message to the logs:</p> <div class=highlight><pre><span></span><code>Using MicroBatchReader [reader] from DataSourceV2 named &#39;[sourceName]&#39; [dataSourceV2]
</code></pre></div> <p>For every other <a href=../../logical-operators/StreamingRelationV2/ >StreamingRelationV2</a> leaf logical operator, <code>logicalPlan</code> tries to replace it with the <a href=../../logical-operators/StreamingExecutionRelation/ >StreamingExecutionRelation</a> that was used earlier for the same <code>StreamingRelationV2</code> (if used multiple times in the plan) or creates a new one. While creating a new <code>StreamingExecutionRelation</code>, <code>logicalPlan</code> requests the <code>StreamingRelation</code> for the underlying <a href=../../logical-operators/StreamingRelation/#dataSource>DataSource</a> that is in turn requested to <a href=../../DataSource/#createSource>create a streaming Source</a> with the metadata path as <code>sources/uniqueID</code> directory in the <a href=../../StreamExecution/#resolvedCheckpointRoot>checkpoint root directory</a>. <code>logicalPlan</code> prints out the following INFO message to the logs:</p> <div class=highlight><pre><span></span><code>Using Source [source] from DataSourceV2 named &#39;[sourceName]&#39; [dataSourceV2]
</code></pre></div> <p><code>logicalPlan</code> requests the transformed analyzed logical plan for all <code>StreamingExecutionRelations</code> that are then requested for <a href=../../logical-operators/StreamingExecutionRelation/#source>BaseStreamingSources</a>, and saves them as the <a href=#sources>sources</a> internal registry.</p> <p>In the end, <code>logicalPlan</code> sets the <a href=../../StreamExecution/#uniqueSources>uniqueSources</a> internal registry to be the unique <code>BaseStreamingSources</code> above.</p> <p><code>logicalPlan</code> throws an <code>AssertionError</code> when not executed on the <a href=../../StreamExecution/#queryExecutionThread>stream execution thread</a>.</p> <div class=highlight><pre><span></span><code>logicalPlan must be initialized in QueryExecutionThread but the current thread was [currentThread]
</code></pre></div> <h2 id=streamingsqlbatchid-local-property><span id=BATCH_ID_KEY><span id=streaming.sql.batchId> streaming.sql.batchId Local Property<a class=headerlink href=#streamingsqlbatchid-local-property title="Permanent link">&para;</a></h2> <p><code>MicroBatchExecution</code> defines <strong>streaming.sql.batchId</strong> as the name of the local property to be the current <strong>batch</strong> or <strong>epoch IDs</strong> (that Spark tasks can use at execution time).</p> <p><code>streaming.sql.batchId</code> is used when:</p> <ul> <li><code>MicroBatchExecution</code> is requested to <a href=#runBatch>run a single streaming micro-batch</a> (and sets the property to be the current batch ID)</li> <li><code>DataWritingSparkTask</code> is requested to run (and needs an epoch ID)</li> </ul> <h2 id=watermarktracker><span id=watermarkTracker> WatermarkTracker<a class=headerlink href=#watermarktracker title="Permanent link">&para;</a></h2> <p><a href=../../WatermarkTracker/ >WatermarkTracker</a> that is created when <code>MicroBatchExecution</code> is requested to <a href=#populateStartOffsets>populate start offsets</a> (when requested to <a href=#runActivatedStream>run an activated streaming query</a>)</p> <h2 id=iscurrentbatchconstructed-flag><span id=isCurrentBatchConstructed> isCurrentBatchConstructed Flag<a class=headerlink href=#iscurrentbatchconstructed-flag title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code><span class=n>isCurrentBatchConstructed</span><span class=k>:</span> <span class=kt>Boolean</span>
</code></pre></div> <p><code>MicroBatchExecution</code> uses <code>isCurrentBatchConstructed</code> internal flag to control whether or not to <a href=#runBatch>run a streaming micro-batch</a>.</p> <p>Default: <code>false</code></p> <p>When <code>false</code>, changed to whatever <a href=#constructNextBatch>constructing the next streaming micro-batch</a> gives back when <a href=#runActivatedStream>running activated streaming query</a></p> <p>Disabled (<code>false</code>) after <a href=#runBatch>running a streaming micro-batch</a> (when enabled after <a href=#constructNextBatch>constructing the next streaming micro-batch</a>)</p> <p>Enabled (<code>true</code>) when <a href=#populateStartOffsets>populating start offsets</a> (when <a href=#runActivatedStream>running an activated streaming query</a>) and <a href=../../HDFSMetadataLog/#getLatest>re-starting a streaming query from a checkpoint</a> (using the <a href=../../StreamExecution/#offsetLog>Offset Write-Ahead Log</a>)</p> <p>Disabled (<code>false</code>) when <a href=#populateStartOffsets>populating start offsets</a> (when <a href=#runActivatedStream>running an activated streaming query</a>) and <a href=../../HDFSMetadataLog/#getLatest>re-starting a streaming query from a checkpoint</a> when the latest offset checkpointed (written) to the <a href=../../StreamExecution/#offsetLog>offset write-ahead log</a> has been successfully processed and <a href=../../HDFSMetadataLog/#getLatest>committed</a> to the <a href=../../StreamExecution/#commitLog>Offset Commit Log</a></p> <h2 id=demo>Demo<a class=headerlink href=#demo title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code>import org.apache.spark.sql.streaming.Trigger
val query = spark
  .readStream
  .format(&quot;rate&quot;)
  .load
  .writeStream
  .format(&quot;console&quot;)          // &lt;-- not a StreamWriteSupport sink
  .option(&quot;truncate&quot;, false)
  .trigger(Trigger.Once)      // &lt;-- Gives MicroBatchExecution
  .queryName(&quot;rate2console&quot;)
  .start

// The following gives access to the internals
// And to MicroBatchExecution
import org.apache.spark.sql.execution.streaming.StreamingQueryWrapper
val engine = query.asInstanceOf[StreamingQueryWrapper].streamingQuery
import org.apache.spark.sql.execution.streaming.StreamExecution
assert(engine.isInstanceOf[StreamExecution])

import org.apache.spark.sql.execution.streaming.MicroBatchExecution
val microBatchEngine = engine.asInstanceOf[MicroBatchExecution]
assert(microBatchEngine.trigger == Trigger.Once)
</code></pre></div> <h2 id=logging>Logging<a class=headerlink href=#logging title="Permanent link">&para;</a></h2> <p>Enable <code>ALL</code> logging level for <code>org.apache.spark.sql.execution.streaming.MicroBatchExecution</code> logger to see what happens inside.</p> <p>Add the following line to <code>conf/log4j.properties</code>:</p> <div class=highlight><pre><span></span><code>log4j.logger.org.apache.spark.sql.execution.streaming.MicroBatchExecution=ALL
</code></pre></div> <p>Refer to <a href=../../spark-logging/ >Logging</a>.</p> <hr> <div class=md-source-date> <small> Last update: 2021-02-07 </small> </div> </article> </div> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../ class="md-footer__link md-footer__link--prev" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Micro-Batch Execution </div> </div> </a> <a href=../MicroBatchWriter/ class="md-footer__link md-footer__link--next" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> MicroBatchWriter </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2021 Jacek Laskowski </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs Insiders </a> </div> <div class=md-footer-social> <a href=https://github.com/jaceklaskowski target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://twitter.com/jaceklaskowski target=_blank rel=noopener title=twitter.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> <a href=https://linkedin.com/in/jaceklaskowski target=_blank rel=noopener title=linkedin.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> </div> </div> </div> </footer> </div> <script src=../../assets/javascripts/vendor.191088e8.min.js></script> <script src=../../assets/javascripts/bundle.d4cf0930.min.js></script><script id=__lang type=application/json>{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script> <script>
        app = initialize({
          base: "../..",
          features: ["navigation.tabs", "navigation.instant", "search.suggest", "navigation.indexes"],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.e77c40e2.min.js"
          }, typeof search !== "undefined" && search),
          version: {}
        })
      </script> </body> </html>