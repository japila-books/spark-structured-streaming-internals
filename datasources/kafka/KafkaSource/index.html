<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Demystifying inner-workings of Spark Structured Streaming"><link href=https://jaceklaskowski.github.io/spark-structured-streaming-book/datasources/kafka/KafkaSource/ rel=canonical><meta name=author content="Jacek Laskowski"><link rel="shortcut icon" href=../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.1.2, mkdocs-material-6.0.2"><title>KafkaSource - The Internals of Spark Structured Streaming</title><link rel=stylesheet href=../../../assets/stylesheets/main.38780c08.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.3f72e892.min.css><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-151208281-3","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview",document.location.pathname)})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-scheme data-md-color-primary=none data-md-color-accent=none> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#kafkasource class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid" aria-label=Header> <a href=https://jaceklaskowski.github.io/spark-structured-streaming-book/ title="The Internals of Spark Structured Streaming" class="md-header-nav__button md-logo" aria-label="The Internals of Spark Structured Streaming"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 2l-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5z"/></svg> </a> <label class="md-header-nav__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header-nav__title data-md-component=header-title> <div class=md-header-nav__ellipsis> <span class="md-header-nav__topic md-ellipsis"> The Internals of Spark Structured Streaming </span> <span class="md-header-nav__topic md-ellipsis"> KafkaSource </span> </div> </div> <label class="md-header-nav__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear data-md-component=search-reset tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header-nav__source> <a href=https://github.com/jaceklaskowski/spark-structured-streaming-book/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> spark-structured-streaming-book </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class="md-tabs md-tabs--active" aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../../operators/ class=md-tabs__link> Streaming Operators </a> </li> <li class=md-tabs__item> <a href=../../ class="md-tabs__link md-tabs__link--active"> Data Sources </a> </li> <li class=md-tabs__item> <a href=../../../monitoring/StreamingQueryListener/ class=md-tabs__link> Monitoring </a> </li> <li class=md-tabs__item> <a href=../../../webui/ class=md-tabs__link> Web UI </a> </li> <li class=md-tabs__item> <a href=../../../demo/spark-sql-streaming-demo-FlatMapGroupsWithStateExec/ class=md-tabs__link> Demos </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=https://jaceklaskowski.github.io/spark-structured-streaming-book/ title="The Internals of Spark Structured Streaming" class="md-nav__button md-logo" aria-label="The Internals of Spark Structured Streaming"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 2l-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5z"/></svg> </a> The Internals of Spark Structured Streaming </label> <div class=md-nav__source> <a href=https://github.com/jaceklaskowski/spark-structured-streaming-book/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> spark-structured-streaming-book </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1 type=checkbox id=nav-1> <label class=md-nav__link for=nav-1> Home <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Home data-md-level=1> <label class=md-nav__title for=nav-1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> Welcome </a> </li> <li class=md-nav__item> <a href=../../../spark-structured-streaming/ class=md-nav__link> Spark Structured Streaming and Streaming Queries </a> </li> <li class=md-nav__item> <a href=../../../spark-structured-streaming-batch-processing-time/ class=md-nav__link> Batch Processing Time </a> </li> <li class=md-nav__item> <a href=../../../spark-structured-streaming-internals/ class=md-nav__link> Internals of Streaming Queries </a> </li> <li class=md-nav__item> <a href=../../../MicroBatchStream/ class=md-nav__link> MicroBatchStream </a> </li> <li class=md-nav__item> <a href=../../../ContinuousStream/ class=md-nav__link> ContinuousStream </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-7 type=checkbox id=nav-1-7> <label class=md-nav__link for=nav-1-7> Streaming Join <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Streaming Join" data-md-level=2> <label class=md-nav__title for=nav-1-7> <span class="md-nav__icon md-icon"></span> Streaming Join </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-join/ class=md-nav__link> Streaming Join </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateStoreAwareZipPartitionsRDD/ class=md-nav__link> StateStoreAwareZipPartitionsRDD </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-7-3 type=checkbox id=nav-1-7-3> <label class=md-nav__link for=nav-1-7-3> SymmetricHashJoinStateManager <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=SymmetricHashJoinStateManager data-md-level=3> <label class=md-nav__title for=nav-1-7-3> <span class="md-nav__icon md-icon"></span> SymmetricHashJoinStateManager </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-SymmetricHashJoinStateManager/ class=md-nav__link> SymmetricHashJoinStateManager </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateStoreHandler/ class=md-nav__link> StateStoreHandler </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-KeyToNumValuesStore/ class=md-nav__link> KeyToNumValuesStore </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-KeyWithIndexToValueStore/ class=md-nav__link> KeyWithIndexToValueStore </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-OneSideHashJoiner/ class=md-nav__link> OneSideHashJoiner </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-JoinStateWatermarkPredicates/ class=md-nav__link> JoinStateWatermarkPredicates </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-JoinStateWatermarkPredicate/ class=md-nav__link> JoinStateWatermarkPredicate </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-7-7 type=checkbox id=nav-1-7-7> <label class=md-nav__link for=nav-1-7-7> StateStoreAwareZipPartitionsHelper <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StateStoreAwareZipPartitionsHelper data-md-level=3> <label class=md-nav__title for=nav-1-7-7> <span class="md-nav__icon md-icon"></span> StateStoreAwareZipPartitionsHelper </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateStoreAwareZipPartitionsHelper/ class=md-nav__link> StateStoreAwareZipPartitionsHelper </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StreamingSymmetricHashJoinHelper/ class=md-nav__link> StreamingSymmetricHashJoinHelper </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StreamingJoinHelper/ class=md-nav__link> StreamingJoinHelper </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-8 type=checkbox id=nav-1-8> <label class=md-nav__link for=nav-1-8> Extending Structured Streaming with New Data Sources <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Extending Structured Streaming with New Data Sources" data-md-level=2> <label class=md-nav__title for=nav-1-8> <span class="md-nav__icon md-icon"></span> Extending Structured Streaming with New Data Sources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-extending-new-data-sources/ class=md-nav__link> Extending Structured Streaming with New Data Sources </a> </li> <li class=md-nav__item> <a href=../../../DataSource/ class=md-nav__link> DataSource </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-9 type=checkbox id=nav-1-9> <label class=md-nav__link for=nav-1-9> Streaming Aggregation <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Streaming Aggregation" data-md-level=2> <label class=md-nav__title for=nav-1-9> <span class="md-nav__icon md-icon"></span> Streaming Aggregation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-aggregation/ class=md-nav__link> Streaming Aggregation </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateStoreRDD/ class=md-nav__link> StateStoreRDD </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateStoreOps/ class=md-nav__link> StateStoreOps </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StreamingAggregationStateManager/ class=md-nav__link> StreamingAggregationStateManager </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StreamingAggregationStateManagerBaseImpl/ class=md-nav__link> StreamingAggregationStateManagerBaseImpl </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StreamingAggregationStateManagerImplV1/ class=md-nav__link> StreamingAggregationStateManagerImplV1 </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StreamingAggregationStateManagerImplV2/ class=md-nav__link> StreamingAggregationStateManagerImplV2 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-10 type=checkbox id=nav-1-10> <label class=md-nav__link for=nav-1-10> Stateful Stream Processing <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Stateful Stream Processing" data-md-level=2> <label class=md-nav__title for=nav-1-10> <span class="md-nav__icon md-icon"></span> Stateful Stream Processing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-stateful-stream-processing/ class=md-nav__link> Stateful Stream Processing </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-watermark/ class=md-nav__link> Streaming Watermark </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-deduplication/ class=md-nav__link> Streaming Deduplication </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-limit/ class=md-nav__link> Streaming Limit </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-10-5 type=checkbox id=nav-1-10-5> <label class=md-nav__link for=nav-1-10-5> StateStore <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StateStore data-md-level=3> <label class=md-nav__title for=nav-1-10-5> <span class="md-nav__icon md-icon"></span> StateStore </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateStore/ class=md-nav__link> StateStore </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateStoreId/ class=md-nav__link> StateStoreId </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-HDFSBackedStateStore/ class=md-nav__link> HDFSBackedStateStore </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-10-6 type=checkbox id=nav-1-10-6> <label class=md-nav__link for=nav-1-10-6> StateStoreProvider <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StateStoreProvider data-md-level=3> <label class=md-nav__title for=nav-1-10-6> <span class="md-nav__icon md-icon"></span> StateStoreProvider </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateStoreProvider/ class=md-nav__link> StateStoreProvider </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateStoreProviderId/ class=md-nav__link> StateStoreProviderId </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-HDFSBackedStateStoreProvider/ class=md-nav__link> HDFSBackedStateStoreProvider </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-10-7 type=checkbox id=nav-1-10-7> <label class=md-nav__link for=nav-1-10-7> StateStoreCoordinator <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StateStoreCoordinator data-md-level=3> <label class=md-nav__title for=nav-1-10-7> <span class="md-nav__icon md-icon"></span> StateStoreCoordinator </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateStoreCoordinator/ class=md-nav__link> StateStoreCoordinator </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateStoreCoordinatorRef/ class=md-nav__link> StateStoreCoordinatorRef </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-WatermarkSupport/ class=md-nav__link> WatermarkSupport </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StatefulOperatorStateInfo/ class=md-nav__link> StatefulOperatorStateInfo </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateStoreMetrics/ class=md-nav__link> StateStoreMetrics </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateStoreCustomMetric/ class=md-nav__link> StateStoreCustomMetric </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateStoreUpdater/ class=md-nav__link> StateStoreUpdater </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-EventTimeStatsAccum/ class=md-nav__link> EventTimeStatsAccum </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateStoreConf/ class=md-nav__link> StateStoreConf </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-11 type=checkbox id=nav-1-11> <label class=md-nav__link for=nav-1-11> Arbitrary Stateful Streaming Aggregation <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Arbitrary Stateful Streaming Aggregation" data-md-level=2> <label class=md-nav__title for=nav-1-11> <span class="md-nav__icon md-icon"></span> Arbitrary Stateful Streaming Aggregation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../arbitrary-stateful-streaming-aggregation/ class=md-nav__link> Arbitrary Stateful Streaming Aggregation </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-11-2 type=checkbox id=nav-1-11-2> <label class=md-nav__link for=nav-1-11-2> KeyValueGroupedDataset <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=KeyValueGroupedDataset data-md-level=3> <label class=md-nav__title for=nav-1-11-2> <span class="md-nav__icon md-icon"></span> KeyValueGroupedDataset </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../KeyValueGroupedDataset/ class=md-nav__link> KeyValueGroupedDataset </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-KeyValueGroupedDataset-mapGroupsWithState/ class=md-nav__link> mapGroupsWithState Operator </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-KeyValueGroupedDataset-flatMapGroupsWithState/ class=md-nav__link> flatMapGroupsWithState Operator </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-11-3 type=checkbox id=nav-1-11-3> <label class=md-nav__link for=nav-1-11-3> GroupState <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=GroupState data-md-level=3> <label class=md-nav__title for=nav-1-11-3> <span class="md-nav__icon md-icon"></span> GroupState </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../GroupState/ class=md-nav__link> GroupState </a> </li> <li class=md-nav__item> <a href=../../../GroupStateImpl/ class=md-nav__link> GroupStateImpl </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-GroupStateTimeout/ class=md-nav__link> GroupStateTimeout </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-11-5 type=checkbox id=nav-1-11-5> <label class=md-nav__link for=nav-1-11-5> StateManager <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StateManager data-md-level=3> <label class=md-nav__title for=nav-1-11-5> <span class="md-nav__icon md-icon"></span> StateManager </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateManager/ class=md-nav__link> StateManager </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateManagerImplV2/ class=md-nav__link> StateManagerImplV2 </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateManagerImplBase/ class=md-nav__link> StateManagerImplBase </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StateManagerImplV1/ class=md-nav__link> StateManagerImplV1 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-FlatMapGroupsWithStateExecHelper/ class=md-nav__link> FlatMapGroupsWithStateExecHelper Helper Class </a> </li> <li class=md-nav__item> <a href=../../../InputProcessor/ class=md-nav__link> InputProcessor </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../StreamingQueryManager/ class=md-nav__link> StreamingQueryManager </a> </li> <li class=md-nav__item> <a href=../../../StreamingQueryListenerBus/ class=md-nav__link> StreamingQueryListenerBus </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-14 type=checkbox id=nav-1-14> <label class=md-nav__link for=nav-1-14> Developing Streaming Applications <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Developing Streaming Applications" data-md-level=2> <label class=md-nav__title for=nav-1-14> <span class="md-nav__icon md-icon"></span> Developing Streaming Applications </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../DataStreamReader/ class=md-nav__link> DataStreamReader </a> </li> <li class=md-nav__item> <a href=../../../SparkDataStream/ class=md-nav__link> SparkDataStream </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-14-3 type=checkbox id=nav-1-14-3> <label class=md-nav__link for=nav-1-14-3> DataStreamWriter <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=DataStreamWriter data-md-level=3> <label class=md-nav__title for=nav-1-14-3> <span class="md-nav__icon md-icon"></span> DataStreamWriter </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../DataStreamWriter/ class=md-nav__link> DataStreamWriter </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-OutputMode/ class=md-nav__link> OutputMode </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-Trigger/ class=md-nav__link> Trigger </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../StreamingQuery/ class=md-nav__link> StreamingQuery </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-window/ class=md-nav__link> window Function </a> </li> <li class=md-nav__item> <a href=../../../SQLConf/ class=md-nav__link> SQLConf </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-properties/ class=md-nav__link> Configuration Properties </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-15 type=checkbox id=nav-1-15> <label class=md-nav__link for=nav-1-15> Query Planning and Execution <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Query Planning and Execution" data-md-level=2> <label class=md-nav__title for=nav-1-15> <span class="md-nav__icon md-icon"></span> Query Planning and Execution </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../StreamExecution/ class=md-nav__link> StreamExecution </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-TriggerExecutor/ class=md-nav__link> TriggerExecutor </a> </li> <li class=md-nav__item> <a href=../../../IncrementalExecution/ class=md-nav__link> IncrementalExecution </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StreamMetadata/ class=md-nav__link> StreamMetadata </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-15-5 type=checkbox id=nav-1-15-5> <label class=md-nav__link for=nav-1-15-5> Logical Operators <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Logical Operators" data-md-level=3> <label class=md-nav__title for=nav-1-15-5> <span class="md-nav__icon md-icon"></span> Logical Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../EventTimeWatermark/ class=md-nav__link> EventTimeWatermark </a> </li> <li class=md-nav__item> <a href=../../../logical-operators/FlatMapGroupsWithState/ class=md-nav__link> FlatMapGroupsWithState </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-Deduplicate/ class=md-nav__link> Deduplicate </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-MemoryPlan/ class=md-nav__link> MemoryPlan </a> </li> <li class=md-nav__item> <a href=../../../StreamingDataSourceV2Relation/ class=md-nav__link> StreamingDataSourceV2Relation </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StreamingRelation/ class=md-nav__link> StreamingRelation </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StreamingRelationV2/ class=md-nav__link> StreamingRelationV2 </a> </li> <li class=md-nav__item> <a href=../../../StreamingExecutionRelation/ class=md-nav__link> StreamingExecutionRelation </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-15-6 type=checkbox id=nav-1-15-6> <label class=md-nav__link for=nav-1-15-6> Physical Operators <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Physical Operators" data-md-level=3> <label class=md-nav__title for=nav-1-15-6> <span class="md-nav__icon md-icon"></span> Physical Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../physical-operators/EventTimeWatermarkExec/ class=md-nav__link> EventTimeWatermarkExec </a> </li> <li class=md-nav__item> <a href=../../../physical-operators/FlatMapGroupsWithStateExec/ class=md-nav__link> FlatMapGroupsWithStateExec </a> </li> <li class=md-nav__item> <a href=../../../physical-operators/StatefulOperator/ class=md-nav__link> StatefulOperator </a> </li> <li class=md-nav__item> <a href=../../../physical-operators/StateStoreReader/ class=md-nav__link> StateStoreReader </a> </li> <li class=md-nav__item> <a href=../../../physical-operators/StateStoreRestoreExec/ class=md-nav__link> StateStoreRestoreExec </a> </li> <li class=md-nav__item> <a href=../../../physical-operators/StateStoreSaveExec/ class=md-nav__link> StateStoreSaveExec </a> </li> <li class=md-nav__item> <a href=../../../physical-operators/StateStoreWriter/ class=md-nav__link> StateStoreWriter </a> </li> <li class=md-nav__item> <a href=../../../physical-operators/StreamingDeduplicateExec/ class=md-nav__link> StreamingDeduplicateExec </a> </li> <li class=md-nav__item> <a href=../../../physical-operators/StreamingGlobalLimitExec/ class=md-nav__link> StreamingGlobalLimitExec </a> </li> <li class=md-nav__item> <a href=../../../physical-operators/StreamingRelationExec/ class=md-nav__link> StreamingRelationExec </a> </li> <li class=md-nav__item> <a href=../../../physical-operators/StreamingSymmetricHashJoinExec/ class=md-nav__link> StreamingSymmetricHashJoinExec </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-15-7 type=checkbox id=nav-1-15-7> <label class=md-nav__link for=nav-1-15-7> Execution Planning Strategies <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Execution Planning Strategies" data-md-level=3> <label class=md-nav__title for=nav-1-15-7> <span class="md-nav__icon md-icon"></span> Execution Planning Strategies </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-FlatMapGroupsWithStateStrategy/ class=md-nav__link> FlatMapGroupsWithStateStrategy </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StatefulAggregationStrategy/ class=md-nav__link> StatefulAggregationStrategy </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StreamingDeduplicationStrategy/ class=md-nav__link> StreamingDeduplicationStrategy </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StreamingGlobalLimitStrategy/ class=md-nav__link> StreamingGlobalLimitStrategy </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StreamingJoinStrategy/ class=md-nav__link> StreamingJoinStrategy </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StreamingRelationStrategy/ class=md-nav__link> StreamingRelationStrategy </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StreamingQueryWrapper/ class=md-nav__link> StreamingQueryWrapper </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-16 type=checkbox id=nav-1-16> <label class=md-nav__link for=nav-1-16> Offsets and Metadata Checkpointing <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Offsets and Metadata Checkpointing" data-md-level=2> <label class=md-nav__title for=nav-1-16> <span class="md-nav__icon md-icon"></span> Offsets and Metadata Checkpointing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-offsets-and-metadata-checkpointing/ class=md-nav__link> Offsets and Metadata Checkpointing </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-MetadataLog/ class=md-nav__link> MetadataLog </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-HDFSMetadataLog/ class=md-nav__link> HDFSMetadataLog </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-16-4 type=checkbox id=nav-1-16-4> <label class=md-nav__link for=nav-1-16-4> CommitLog <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=CommitLog data-md-level=3> <label class=md-nav__title for=nav-1-16-4> <span class="md-nav__icon md-icon"></span> CommitLog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-CommitLog/ class=md-nav__link> CommitLog </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-CommitMetadata/ class=md-nav__link> CommitMetadata </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-16-5 type=checkbox id=nav-1-16-5> <label class=md-nav__link for=nav-1-16-5> OffsetSeqLog <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=OffsetSeqLog data-md-level=3> <label class=md-nav__title for=nav-1-16-5> <span class="md-nav__icon md-icon"></span> OffsetSeqLog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-OffsetSeqLog/ class=md-nav__link> OffsetSeqLog </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-OffsetSeq/ class=md-nav__link> OffsetSeq </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-16-6 type=checkbox id=nav-1-16-6> <label class=md-nav__link for=nav-1-16-6> CompactibleFileStreamLog <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=CompactibleFileStreamLog data-md-level=3> <label class=md-nav__title for=nav-1-16-6> <span class="md-nav__icon md-icon"></span> CompactibleFileStreamLog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../CompactibleFileStreamLog/ class=md-nav__link> CompactibleFileStreamLog </a> </li> <li class=md-nav__item> <a href=../../file/FileStreamSourceLog/ class=md-nav__link> FileStreamSourceLog </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-OffsetSeqMetadata/ class=md-nav__link> OffsetSeqMetadata </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-16-8 type=checkbox id=nav-1-16-8> <label class=md-nav__link for=nav-1-16-8> CheckpointFileManager <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=CheckpointFileManager data-md-level=3> <label class=md-nav__title for=nav-1-16-8> <span class="md-nav__icon md-icon"></span> CheckpointFileManager </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-CheckpointFileManager/ class=md-nav__link> CheckpointFileManager </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-FileContextBasedCheckpointFileManager/ class=md-nav__link> FileContextBasedCheckpointFileManager </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-FileSystemBasedCheckpointFileManager/ class=md-nav__link> FileSystemBasedCheckpointFileManager </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-Offset/ class=md-nav__link> Offset </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-StreamProgress/ class=md-nav__link> StreamProgress </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-17 type=checkbox id=nav-1-17> <label class=md-nav__link for=nav-1-17> Micro-Batch Stream Processing <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Micro-Batch Stream Processing" data-md-level=2> <label class=md-nav__title for=nav-1-17> <span class="md-nav__icon md-icon"></span> Micro-Batch Stream Processing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../micro-batch-stream-processing/ class=md-nav__link> Micro-Batch Stream Processing </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-17-2 type=checkbox id=nav-1-17-2> <label class=md-nav__link for=nav-1-17-2> MicroBatchExecution <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=MicroBatchExecution data-md-level=3> <label class=md-nav__title for=nav-1-17-2> <span class="md-nav__icon md-icon"></span> MicroBatchExecution </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../MicroBatchExecution/ class=md-nav__link> MicroBatchExecution </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-MicroBatchWriter/ class=md-nav__link> MicroBatchWriter </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-17-3 type=checkbox id=nav-1-17-3> <label class=md-nav__link for=nav-1-17-3> MicroBatchReadSupport <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=MicroBatchReadSupport data-md-level=3> <label class=md-nav__title for=nav-1-17-3> <span class="md-nav__icon md-icon"></span> MicroBatchReadSupport </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../MicroBatchReadSupport/ class=md-nav__link> MicroBatchReadSupport </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-MicroBatchReader/ class=md-nav__link> MicroBatchReader </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-WatermarkTracker/ class=md-nav__link> WatermarkTracker </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-17-5 type=checkbox id=nav-1-17-5> <label class=md-nav__link for=nav-1-17-5> Source <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Source data-md-level=3> <label class=md-nav__title for=nav-1-17-5> <span class="md-nav__icon md-icon"></span> Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Source/ class=md-nav__link> Source </a> </li> <li class=md-nav__item> <a href=../../../StreamSourceProvider/ class=md-nav__link> StreamSourceProvider </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../Sink/ class=md-nav__link> Sink </a> </li> <li class=md-nav__item> <a href=../../../StreamSinkProvider/ class=md-nav__link> StreamSinkProvider </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-18 type=checkbox id=nav-1-18> <label class=md-nav__link for=nav-1-18> Continuous Stream Processing <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Continuous Stream Processing" data-md-level=2> <label class=md-nav__title for=nav-1-18> <span class="md-nav__icon md-icon"></span> Continuous Stream Processing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-continuous-stream-processing/ class=md-nav__link> Continuous Stream Processing </a> </li> <li class=md-nav__item> <a href=../../../ContinuousExecution/ class=md-nav__link> ContinuousExecution </a> </li> <li class=md-nav__item> <a href=../../../ContinuousReadSupport/ class=md-nav__link> ContinuousReadSupport </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-ContinuousReader/ class=md-nav__link> ContinuousReader </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-RateStreamContinuousReader/ class=md-nav__link> RateStreamContinuousReader </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-18-6 type=checkbox id=nav-1-18-6> <label class=md-nav__link for=nav-1-18-6> EpochCoordinator <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=EpochCoordinator data-md-level=3> <label class=md-nav__title for=nav-1-18-6> <span class="md-nav__icon md-icon"></span> EpochCoordinator </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-EpochCoordinator/ class=md-nav__link> EpochCoordinator RPC Endpoint </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-EpochCoordinatorRef/ class=md-nav__link> EpochCoordinatorRef </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-EpochTracker/ class=md-nav__link> EpochTracker </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-18-7 type=checkbox id=nav-1-18-7> <label class=md-nav__link for=nav-1-18-7> ContinuousQueuedDataReader <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=ContinuousQueuedDataReader data-md-level=3> <label class=md-nav__title for=nav-1-18-7> <span class="md-nav__icon md-icon"></span> ContinuousQueuedDataReader </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-ContinuousQueuedDataReader/ class=md-nav__link> ContinuousQueuedDataReader </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-ContinuousQueuedDataReader-DataReaderThread/ class=md-nav__link> DataReaderThread </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-ContinuousQueuedDataReader-EpochMarkerGenerator/ class=md-nav__link> EpochMarkerGenerator </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-PartitionOffset/ class=md-nav__link> PartitionOffset </a> </li> <li class=md-nav__item> <a href=../../../ContinuousExecutionRelation/ class=md-nav__link> ContinuousExecutionRelation </a> </li> <li class=md-nav__item> <a href=../../../WriteToContinuousDataSource/ class=md-nav__link> WriteToContinuousDataSource </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-18-11 type=checkbox id=nav-1-18-11> <label class=md-nav__link for=nav-1-18-11> WriteToContinuousDataSourceExec <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=WriteToContinuousDataSourceExec data-md-level=3> <label class=md-nav__title for=nav-1-18-11> <span class="md-nav__icon md-icon"></span> WriteToContinuousDataSourceExec </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-WriteToContinuousDataSourceExec/ class=md-nav__link> WriteToContinuousDataSourceExec Unary Physical Operator </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-ContinuousWriteRDD/ class=md-nav__link> ContinuousWriteRDD </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-ContinuousDataSourceRDD/ class=md-nav__link> ContinuousDataSourceRDD </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-UnsupportedOperationChecker/ class=md-nav__link> UnsupportedOperationChecker </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2 type=checkbox id=nav-2> <label class=md-nav__link for=nav-2> Streaming Operators <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Streaming Operators" data-md-level=1> <label class=md-nav__title for=nav-2> <span class="md-nav__icon md-icon"></span> Streaming Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../operators/ class=md-nav__link> Streaming Operators </a> </li> <li class=md-nav__item> <a href=../../../operators/crossJoin/ class=md-nav__link> crossJoin </a> </li> <li class=md-nav__item> <a href=../../../operators/dropDuplicates/ class=md-nav__link> dropDuplicates </a> </li> <li class=md-nav__item> <a href=../../../operators/explain/ class=md-nav__link> explain </a> </li> <li class=md-nav__item> <a href=../../../operators/flatMapGroupsWithState/ class=md-nav__link> flatMapGroupsWithState </a> </li> <li class=md-nav__item> <a href=../../../operators/groupBy/ class=md-nav__link> groupBy </a> </li> <li class=md-nav__item> <a href=../../../operators/groupByKey/ class=md-nav__link> groupByKey </a> </li> <li class=md-nav__item> <a href=../../../operators/join/ class=md-nav__link> join </a> </li> <li class=md-nav__item> <a href=../../../operators/joinWith/ class=md-nav__link> joinWith </a> </li> <li class=md-nav__item> <a href=../../../operators/withWatermark/ class=md-nav__link> withWatermark </a> </li> <li class=md-nav__item> <a href=../../../operators/writeStream/ class=md-nav__link> writeStream </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3 type=checkbox id=nav-3 checked> <label class=md-nav__link for=nav-3> Data Sources <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Data Sources" data-md-level=1> <label class=md-nav__title for=nav-3> <span class="md-nav__icon md-icon"></span> Data Sources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../ class=md-nav__link> Data Sources </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-2 type=checkbox id=nav-3-2> <label class=md-nav__link for=nav-3-2> File Data Source <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="File Data Source" data-md-level=2> <label class=md-nav__title for=nav-3-2> <span class="md-nav__icon md-icon"></span> File Data Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../file/ class=md-nav__link> File Data Source </a> </li> <li class=md-nav__item> <a href=../../file/FileStreamSource/ class=md-nav__link> FileStreamSource </a> </li> <li class=md-nav__item> <a href=../../file/FileStreamSink/ class=md-nav__link> FileStreamSink </a> </li> <li class=md-nav__item> <a href=../../file/FileStreamSinkLog/ class=md-nav__link> FileStreamSinkLog </a> </li> <li class=md-nav__item> <a href=../../file/SinkFileStatus/ class=md-nav__link> SinkFileStatus </a> </li> <li class=md-nav__item> <a href=../../file/ManifestFileCommitProtocol/ class=md-nav__link> ManifestFileCommitProtocol </a> </li> <li class=md-nav__item> <a href=../../file/MetadataLogFileIndex/ class=md-nav__link> MetadataLogFileIndex </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-3 type=checkbox id=nav-3-3 checked> <label class=md-nav__link for=nav-3-3> Kafka Data Source <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Kafka Data Source" data-md-level=2> <label class=md-nav__title for=nav-3-3> <span class="md-nav__icon md-icon"></span> Kafka Data Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ class=md-nav__link> Kafka Data Source </a> </li> <li class=md-nav__item> <a href=../KafkaSourceProvider/ class=md-nav__link> KafkaSourceProvider </a> </li> <li class=md-nav__item> <a href=../KafkaTable/ class=md-nav__link> KafkaTable </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <a href=./ class="md-nav__link md-nav__link--active"> KafkaSource </a> </li> <li class=md-nav__item> <a href=../KafkaRelation/ class=md-nav__link> KafkaRelation </a> </li> <li class=md-nav__item> <a href=../KafkaSourceRDD/ class=md-nav__link> KafkaSourceRDD </a> </li> <li class=md-nav__item> <a href=../CachedKafkaConsumer/ class=md-nav__link> CachedKafkaConsumer </a> </li> <li class=md-nav__item> <a href=../KafkaSourceOffset/ class=md-nav__link> KafkaSourceOffset </a> </li> <li class=md-nav__item> <a href=../KafkaOffsetReader/ class=md-nav__link> KafkaOffsetReader </a> </li> <li class=md-nav__item> <a href=../ConsumerStrategy/ class=md-nav__link> ConsumerStrategy </a> </li> <li class=md-nav__item> <a href=../KafkaSink/ class=md-nav__link> KafkaSink </a> </li> <li class=md-nav__item> <a href=../KafkaBatch/ class=md-nav__link> KafkaBatch </a> </li> <li class=md-nav__item> <a href=../KafkaScan/ class=md-nav__link> KafkaScan </a> </li> <li class=md-nav__item> <a href=../KafkaOffsetRangeLimit/ class=md-nav__link> KafkaOffsetRangeLimit </a> </li> <li class=md-nav__item> <a href=../KafkaDataConsumer/ class=md-nav__link> KafkaDataConsumer </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-3-16 type=checkbox id=nav-3-3-16> <label class=md-nav__link for=nav-3-3-16> KafkaMicroBatchReader <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=KafkaMicroBatchReader data-md-level=3> <label class=md-nav__title for=nav-3-3-16> <span class="md-nav__icon md-icon"></span> KafkaMicroBatchReader </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../KafkaMicroBatchReader/ class=md-nav__link> KafkaMicroBatchReader </a> </li> <li class=md-nav__item> <a href=../KafkaOffsetRangeCalculator/ class=md-nav__link> KafkaOffsetRangeCalculator </a> </li> <li class=md-nav__item> <a href=../KafkaMicroBatchInputPartition/ class=md-nav__link> KafkaMicroBatchInputPartition </a> </li> <li class=md-nav__item> <a href=../KafkaMicroBatchInputPartitionReader/ class=md-nav__link> KafkaMicroBatchInputPartitionReader </a> </li> <li class=md-nav__item> <a href=../KafkaSourceInitialOffsetWriter/ class=md-nav__link> KafkaSourceInitialOffsetWriter </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-3-17 type=checkbox id=nav-3-3-17> <label class=md-nav__link for=nav-3-3-17> KafkaContinuousReader <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=KafkaContinuousReader data-md-level=3> <label class=md-nav__title for=nav-3-3-17> <span class="md-nav__icon md-icon"></span> KafkaContinuousReader </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../KafkaContinuousReader/ class=md-nav__link> KafkaContinuousReader </a> </li> <li class=md-nav__item> <a href=../KafkaContinuousInputPartition/ class=md-nav__link> KafkaContinuousInputPartition </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-4 type=checkbox id=nav-3-4> <label class=md-nav__link for=nav-3-4> Text Socket Data Source <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Text Socket Data Source" data-md-level=2> <label class=md-nav__title for=nav-3-4> <span class="md-nav__icon md-icon"></span> Text Socket Data Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-TextSocketSourceProvider/ class=md-nav__link> TextSocketSourceProvider </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-TextSocketSource/ class=md-nav__link> TextSocketSource </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-5 type=checkbox id=nav-3-5> <label class=md-nav__link for=nav-3-5> Rate Data Source <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Rate Data Source" data-md-level=2> <label class=md-nav__title for=nav-3-5> <span class="md-nav__icon md-icon"></span> Rate Data Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-RateSourceProvider/ class=md-nav__link> RateSourceProvider </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-RateStreamProvider/ class=md-nav__link> RateStreamProvider </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-RateStreamSource/ class=md-nav__link> RateStreamSource </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-RateStreamMicroBatchReader/ class=md-nav__link> RateStreamMicroBatchReader </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-6 type=checkbox id=nav-3-6> <label class=md-nav__link for=nav-3-6> Console Data Sink <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Console Data Sink" data-md-level=2> <label class=md-nav__title for=nav-3-6> <span class="md-nav__icon md-icon"></span> Console Data Sink </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-ConsoleSinkProvider/ class=md-nav__link> ConsoleSinkProvider </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-ConsoleWriter/ class=md-nav__link> ConsoleWriter </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-7 type=checkbox id=nav-3-7> <label class=md-nav__link for=nav-3-7> Foreach Data Sink <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Foreach Data Sink" data-md-level=2> <label class=md-nav__title for=nav-3-7> <span class="md-nav__icon md-icon"></span> Foreach Data Sink </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-ForeachWriterProvider/ class=md-nav__link> ForeachWriterProvider </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-ForeachWriter/ class=md-nav__link> ForeachWriter </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-ForeachSink/ class=md-nav__link> ForeachSink </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-8 type=checkbox id=nav-3-8> <label class=md-nav__link for=nav-3-8> ForeachBatch Data Sink <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="ForeachBatch Data Sink" data-md-level=2> <label class=md-nav__title for=nav-3-8> <span class="md-nav__icon md-icon"></span> ForeachBatch Data Sink </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-ForeachBatchSink/ class=md-nav__link> ForeachBatchSink </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-9 type=checkbox id=nav-3-9> <label class=md-nav__link for=nav-3-9> Memory Data Source <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Memory Data Source" data-md-level=2> <label class=md-nav__title for=nav-3-9> <span class="md-nav__icon md-icon"></span> Memory Data Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-memory-data-source/ class=md-nav__link> Memory Data Source </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-MemoryStream/ class=md-nav__link> MemoryStream </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-ContinuousMemoryStream/ class=md-nav__link> ContinuousMemoryStream </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-MemorySink/ class=md-nav__link> MemorySink </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-9-5 type=checkbox id=nav-3-9-5> <label class=md-nav__link for=nav-3-9-5> MemorySinkV2 <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=MemorySinkV2 data-md-level=3> <label class=md-nav__title for=nav-3-9-5> <span class="md-nav__icon md-icon"></span> MemorySinkV2 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../spark-sql-streaming-MemorySinkV2/ class=md-nav__link> MemorySinkV2 </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-MemoryStreamWriter/ class=md-nav__link> MemoryStreamWriter </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-MemoryStreamBase/ class=md-nav__link> MemoryStreamBase </a> </li> <li class=md-nav__item> <a href=../../../spark-sql-streaming-MemorySinkBase/ class=md-nav__link> MemorySinkBase </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4 type=checkbox id=nav-4> <label class=md-nav__link for=nav-4> Monitoring <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Monitoring data-md-level=1> <label class=md-nav__title for=nav-4> <span class="md-nav__icon md-icon"></span> Monitoring </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../monitoring/StreamingQueryListener/ class=md-nav__link> StreamingQueryListener </a> </li> <li class=md-nav__item> <a href=../../../monitoring/ProgressReporter/ class=md-nav__link> ProgressReporter </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-3 type=checkbox id=nav-4-3> <label class=md-nav__link for=nav-4-3> StreamingQueryProgress <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StreamingQueryProgress data-md-level=2> <label class=md-nav__title for=nav-4-3> <span class="md-nav__icon md-icon"></span> StreamingQueryProgress </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../monitoring/StreamingQueryProgress/ class=md-nav__link> StreamingQueryProgress </a> </li> <li class=md-nav__item> <a href=../../../monitoring/StateOperatorProgress/ class=md-nav__link> StateOperatorProgress </a> </li> <li class=md-nav__item> <a href=../../../monitoring/ExecutionStats/ class=md-nav__link> ExecutionStats </a> </li> <li class=md-nav__item> <a href=../../../monitoring/SourceProgress/ class=md-nav__link> SourceProgress </a> </li> <li class=md-nav__item> <a href=../../../monitoring/SinkProgress/ class=md-nav__link> SinkProgress </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../monitoring/StreamingQueryStatus/ class=md-nav__link> StreamingQueryStatus </a> </li> <li class=md-nav__item> <a href=../../../monitoring/MetricsReporter/ class=md-nav__link> MetricsReporter </a> </li> <li class=md-nav__item> <a href=../../../spark-logging/ class=md-nav__link> Logging </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-5 type=checkbox id=nav-5> <label class=md-nav__link for=nav-5> Web UI <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Web UI" data-md-level=1> <label class=md-nav__title for=nav-5> <span class="md-nav__icon md-icon"></span> Web UI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../webui/ class=md-nav__link> Web UI </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-6 type=checkbox id=nav-6> <label class=md-nav__link for=nav-6> Demos <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Demos data-md-level=1> <label class=md-nav__title for=nav-6> <span class="md-nav__icon md-icon"></span> Demos </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../demo/spark-sql-streaming-demo-FlatMapGroupsWithStateExec/ class=md-nav__link> Internals of FlatMapGroupsWithStateExec Physical Operator </a> </li> <li class=md-nav__item> <a href=../../../demo/arbitrary-stateful-streaming-aggregation-flatMapGroupsWithState/ class=md-nav__link> Arbitrary Stateful Streaming Aggregation with KeyValueGroupedDataset.flatMapGroupsWithState Operator </a> </li> <li class=md-nav__item> <a href=../../../demo/exploring-checkpointed-state/ class=md-nav__link> Exploring Checkpointed State </a> </li> <li class=md-nav__item> <a href=../../../demo/watermark-aggregation-append/ class=md-nav__link> Streaming Watermark with Aggregation in Append Output Mode </a> </li> <li class=md-nav__item> <a href=../../../demo/groupBy-running-count-complete/ class=md-nav__link> Streaming Query for Running Counts (Socket Source and Complete Output Mode) </a> </li> <li class=md-nav__item> <a href=../../../demo/kafka-data-source/ class=md-nav__link> Streaming Aggregation with Kafka Data Source </a> </li> <li class=md-nav__item> <a href=../../../demo/groupByKey-count-Update/ class=md-nav__link> groupByKey Streaming Aggregation in Update Mode </a> </li> <li class=md-nav__item> <a href=../../../demo/StateStoreSaveExec-Complete/ class=md-nav__link> StateStoreSaveExec with Complete Output Mode </a> </li> <li class=md-nav__item> <a href=../../../demo/StateStoreSaveExec-Update/ class=md-nav__link> StateStoreSaveExec with Update Output Mode </a> </li> <li class=md-nav__item> <a href=../../../demo/custom-sink-webui/ class=md-nav__link> Developing Custom Streaming Sink (and Monitoring SQL Queries in web UI) </a> </li> <li class=md-nav__item> <a href=../../../demo/current_timestamp/ class=md-nav__link> current_timestamp Function For Processing Time in Streaming Queries </a> </li> <li class=md-nav__item> <a href=../../../demo/StreamingQueryManager-awaitAnyTermination-resetTerminated/ class=md-nav__link> Using StreamingQueryManager for Query Termination Management </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <a href=https://github.com/jaceklaskowski/spark-structured-streaming-book/edit/mkdocs-material/docs/datasources/kafka/KafkaSource.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1 id=kafkasource>KafkaSource<a class=headerlink href=#kafkasource title="Permanent link">&para;</a></h1> <p><code>KafkaSource</code> is a <a href=../../../Source/ >streaming source</a> that &lt;<getbatch, generates dataframes of records from one or more topics in apache kafka>&gt;.</p> <p>NOTE: Kafka topics are checked for new records every spark-sql-streaming-Trigger.md[trigger] and so there is some noticeable delay between when the records have arrived to Kafka topics and when a Spark application processes them.</p> <p><code>KafkaSource</code> uses the &lt;<metadatapath, streaming metadata log directory>&gt; to persist offsets. The directory is the source ID under the <code>sources</code> directory in the <a href=../../../StreamExecution/#checkpointRoot>checkpointRoot</a> (of the <a href=../../../StreamExecution/ >StreamExecution</a>).</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p>The <a href=../../../StreamExecution/#checkpointRoot>checkpointRoot</a> directory is one of the following:</p> <ul> <li><code>checkpointLocation</code> option</li> <li><a href=../../../spark-sql-streaming-properties/#spark.sql.streaming.checkpointLocation>spark.sql.streaming.checkpointLocation</a> configuration property</li> </ul> </div> <p><code>KafkaSource</code> &lt;<creating-instance, is created>&gt; for <em>kafka</em> format (that is registered by <a href=../KafkaSourceProvider/#shortName>KafkaSourceProvider</a>).</p> <p>.KafkaSource Is Created for kafka Format by KafkaSourceProvider image::images/KafkaSource-creating-instance.png[align="center"]</p> <p>[[schema]] <code>KafkaSource</code> uses a <a href=../#schema>predefined (fixed) schema</a> (that <a href=../KafkaSourceProvider/#sourceSchema>cannot be changed</a>).</p> <p><code>KafkaSource</code> also supports batch Datasets.</p> <p>[[logging]] [TIP] ==== Enable <code>ALL</code> logging level for <code>org.apache.spark.sql.kafka010.KafkaSource</code> to see what happens inside.</p> <p>Add the following line to <code>conf/log4j.properties</code>:</p> <div class=highlight><pre><span></span><code>log4j.logger.org.apache.spark.sql.kafka010.KafkaSource=ALL
</code></pre></div> <h1 id=refer-to>Refer to &lt;<spark-sql-streaming-spark-logging.md#, logging>&gt;.<a class=headerlink href=#refer-to title="Permanent link">&para;</a></h1> <h2 id=creating-instance>Creating Instance<a class=headerlink href=#creating-instance title="Permanent link">&para;</a></h2> <p><code>KafkaSource</code> takes the following to be created:</p> <ul> <li>[[sqlContext]] <code>SQLContext</code></li> <li>[[kafkaReader]] <a href=../KafkaOffsetReader/ >KafkaOffsetReader</a></li> <li>[[executorKafkaParams]] Parameters of executors (reading from Kafka)</li> <li>[[sourceOptions]] Collection of key-value options</li> <li>[[metadataPath]] <em>Streaming metadata log directory</em>, i.e. the directory for streaming metadata log (where <code>KafkaSource</code> persists <a href=../KafkaSourceOffset/ >KafkaSourceOffset</a> offsets in JSON format)</li> <li>[[startingOffsets]] <a href=../KafkaOffsetRangeLimit/ >Starting offsets</a> (as defined using <a href=../#startingOffsets>startingOffsets</a> option)</li> <li>[[failOnDataLoss]] Flag used to create <a href=../KafkaSourceRDD/ >KafkaSourceRDD</a>s every trigger and when checking to <a href=#reportDataLoss>report a IllegalStateException on data loss</a>.</li> </ul> <p><code>KafkaSource</code> initializes the &lt;<internal-properties, internal properties>&gt;.</p> <p>=== [[getBatch]] Generating Streaming DataFrame with Records From Kafka for Streaming Micro-Batch -- <code>getBatch</code> Method</p> <h2 id=source-scala>[source, scala]<a class=headerlink href=#source-scala title="Permanent link">&para;</a></h2> <p>getBatch( start: Option[Offset], end: Offset): DataFrame</p> <hr> <p><code>getBatch</code> is part of the <a href=../../../Source/#getBatch>Source</a> abstraction.</p> <p><code>getBatch</code> creates a streaming <code>DataFrame</code> with a query plan with <code>LogicalRDD</code> logical operator to scan data from a <a href=../KafkaSourceRDD/ >KafkaSourceRDD</a>.</p> <p>Internally, <code>getBatch</code> initializes &lt;<initialpartitionoffsets, initial partition offsets>&gt; (unless initialized already).</p> <p>You should see the following INFO message in the logs:</p> <div class=highlight><pre><span></span><code>GetBatch called with start = [start], end = [end]
</code></pre></div> <p><code>getBatch</code> requests <code>KafkaSourceOffset</code> for <a href=../KafkaSourceOffset/#getPartitionOffsets>end partition offsets</a> for the input <code>end</code> offset (known as <code>untilPartitionOffsets</code>).</p> <p><code>getBatch</code> requests <code>KafkaSourceOffset</code> for <a href=../KafkaSourceOffset/#getPartitionOffsets>start partition offsets</a> for the input <code>start</code> offset (if defined) or uses &lt;<initialpartitionoffsets, initial partition offsets>&gt; (known as <code>fromPartitionOffsets</code>).</p> <p><code>getBatch</code> finds the new partitions (as the difference between the topic partitions in <code>untilPartitionOffsets</code> and <code>fromPartitionOffsets</code>) and requests &lt;<kafkareader, kafkaoffsetreader>&gt; to <a href=../KafkaOffsetReader/#fetchEarliestOffsets>fetch their earliest offsets</a>.</p> <p><code>getBatch</code> &lt;<reportdataloss, reports a data loss>&gt; if the new partitions don't match to what &lt;<kafkareader, kafkaoffsetreader>&gt; fetched.</p> <div class=highlight><pre><span></span><code>Cannot find earliest offsets of [partitions]. Some data may have been missed
</code></pre></div> <p>You should see the following INFO message in the logs:</p> <div class=highlight><pre><span></span><code>Partitions added: [newPartitionOffsets]
</code></pre></div> <p><code>getBatch</code> &lt;<reportdataloss, reports a data loss>&gt; if the new partitions don't have their offsets <code>0</code>.</p> <div class=highlight><pre><span></span><code>Added partition [partition] starts from [offset] instead of 0. Some data may have been missed
</code></pre></div> <p><code>getBatch</code> &lt;<reportdataloss, reports a data loss>&gt; if the <code>fromPartitionOffsets</code> partitions differ from <code>untilPartitionOffsets</code> partitions.</p> <div class=highlight><pre><span></span><code>[partitions] are gone. Some data may have been missed
</code></pre></div> <p>You should see the following DEBUG message in the logs:</p> <div class=highlight><pre><span></span><code>TopicPartitions: [topicPartitions]
</code></pre></div> <p><code>getBatch</code> &lt;<getsortedexecutorlist, gets the executors>&gt; (sorted by <code>executorId</code> and <code>host</code> of the registered block managers).</p> <p>IMPORTANT: That is when <code>getBatch</code> goes very low-level to allow for cached <code>KafkaConsumers</code> in the executors to be re-used to read the same partition in every batch (aka <em>location preference</em>).</p> <p>You should see the following DEBUG message in the logs:</p> <div class=highlight><pre><span></span><code>Sorted executors: [sortedExecutors]
</code></pre></div> <p><code>getBatch</code> creates a <code>KafkaSourceRDDOffsetRange</code> per <code>TopicPartition</code>.</p> <p><code>getBatch</code> filters out <code>KafkaSourceRDDOffsetRanges</code> for which until offsets are smaller than from offsets. <code>getBatch</code> &lt;<reportdataloss, reports a data loss>&gt; if they are found.</p> <div class=highlight><pre><span></span><code>Partition [topicPartition]&#39;s offset was changed from [fromOffset] to [untilOffset], some data may have been missed
</code></pre></div> <p><code>getBatch</code> creates a <a href=../KafkaSourceRDD/ >KafkaSourceRDD</a> (with &lt;<executorkafkaparams, executorkafkaparams>&gt;, &lt;<polltimeoutms, polltimeoutms>&gt; and <code>reuseKafkaConsumer</code> flag enabled) and maps it to an RDD of <code>InternalRow</code>.</p> <p>IMPORTANT: <code>getBatch</code> creates a <code>KafkaSourceRDD</code> with <code>reuseKafkaConsumer</code> flag enabled.</p> <p>You should see the following INFO message in the logs:</p> <div class=highlight><pre><span></span><code>GetBatch generating RDD of offset range: [offsetRanges]
</code></pre></div> <p><code>getBatch</code> sets &lt;<currentpartitionoffsets, currentpartitionoffsets>&gt; if it was empty (which is when...FIXME)</p> <p>In the end, <code>getBatch</code> creates a streaming <code>DataFrame</code> for the <code>KafkaSourceRDD</code> and the &lt;<schema, schema>&gt;.</p> <p>=== [[getOffset]] Fetching Offsets (From Metadata Log or Kafka Directly) -- <code>getOffset</code> Method</p> <h2 id=source-scala_1>[source, scala]<a class=headerlink href=#source-scala_1 title="Permanent link">&para;</a></h2> <h2 id=getoffset-optionoffset>getOffset: Option[Offset]<a class=headerlink href=#getoffset-optionoffset title="Permanent link">&para;</a></h2> <p>NOTE: <code>getOffset</code> is a part of the ../../Source.md#getOffset[Source Contract].</p> <p>Internally, <code>getOffset</code> fetches the &lt;<initialpartitionoffsets, initial partition offsets>&gt; (from the metadata log or Kafka directly).</p> <p>.KafkaSource Initializing initialPartitionOffsets While Fetching Initial Offsets image::images/KafkaSource-initialPartitionOffsets.png[align="center"]</p> <p>NOTE: &lt;<initialpartitionoffsets, initialpartitionoffsets>&gt; is a lazy value and is initialized the very first time <code>getOffset</code> is called (which is when <code>StreamExecution</code> MicroBatchExecution.md#constructNextBatch-hasNewData[constructs a streaming micro-batch]).</p> <h2 id=source-scala_2>[source, scala]<a class=headerlink href=#source-scala_2 title="Permanent link">&para;</a></h2> <p>scala&gt; spark.version res0: String = 2.3.0-SNAPSHOT</p> <p>// Case 1: Checkpoint directory undefined // initialPartitionOffsets read from Kafka directly val records = spark. readStream. format("kafka"). option("subscribe", "topic1"). option("kafka.bootstrap.servers", "localhost:9092"). load // Start the streaming query // dump records to the console every 10 seconds import org.apache.spark.sql.streaming.{OutputMode, Trigger} import scala.concurrent.duration._ val q = records. writeStream. format("console"). option("truncate", false). trigger(Trigger.ProcessingTime(10.seconds)). outputMode(OutputMode.Update). start // Note the temporary checkpoint directory 17/08/07 11:09:29 INFO StreamExecution: Starting [id = 75dd261d-6b62-40fc-a368-9d95d3cb6f5f, runId = f18a5eb5-ccab-4d9d-8a81-befed41a72bd] with file:///private/var/folders/0w/kb0d3rqn4zb9fcc91pxhgn8w0000gn/T/temporary-d0055630-24e4-4d9a-8f36-7a12a0f11bc0 to store the query checkpoint. ... INFO KafkaSource: Initial offsets: {"topic1":{"0":1}}</p> <p>// Stop the streaming query q.stop</p> <p>// Case 2: Checkpoint directory defined // initialPartitionOffsets read from Kafka directly // since the checkpoint directory is not available yet // it will be the next time the query is started val records = spark. readStream. format("kafka"). option("subscribe", "topic1"). option("kafka.bootstrap.servers", "localhost:9092"). load. select($"value" cast "string", $"topic", $"partition", $"offset") import org.apache.spark.sql.streaming.{OutputMode, Trigger} import scala.concurrent.duration._ val q = records. writeStream. format("console"). option("truncate", false). option("checkpointLocation", "/tmp/checkpoint"). // &larr; checkpoint directory trigger(Trigger.ProcessingTime(10.seconds)). outputMode(OutputMode.Update). start // Note the checkpoint directory in use 17/08/07 11:21:25 INFO StreamExecution: Starting [id = b8f59854-61c1-4c2f-931d-62bbaf90ee3b, runId = 70d06a3b-f2b1-4fa8-a518-15df4cf59130] with file:///tmp/checkpoint to store the query checkpoint. ... INFO KafkaSource: Initial offsets: {"topic1":{"0":1}} ... INFO StreamExecution: Stored offsets for batch 0. Metadata OffsetSeqMetadata(0,1502098526848,Map(spark.sql.shuffle.partitions -&gt; 200, spark.sql.streaming.stateStore.providerClass -&gt; org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))</p> <p>// Review the checkpoint location // $ ls -ltr /tmp/checkpoint/offsets // total 8 // -rw-r--r-- 1 jacek wheel 248 7 sie 11:21 0 // $ tail -2 /tmp/checkpoint/offsets/0 | jq</p> <p>// Produce messages to Kafka so the latest offset changes // And more importanly the offset gets stored to checkpoint location</p> <hr> <h2 id=batch-1>Batch: 1<a class=headerlink href=#batch-1 title="Permanent link">&para;</a></h2> <p>+---------------------------+------+---------+------+ |value |topic |partition|offset| +---------------------------+------+---------+------+ |testing checkpoint location|topic1|0 |2 | +---------------------------+------+---------+------+</p> <p>// and one more // Note the offset</p> <hr> <h2 id=batch-2>Batch: 2<a class=headerlink href=#batch-2 title="Permanent link">&para;</a></h2> <p>+------------+------+---------+------+ |value |topic |partition|offset| +------------+------+---------+------+ |another test|topic1|0 |3 | +------------+------+---------+------+</p> <p>// See what was checkpointed // $ ls -ltr /tmp/checkpoint/offsets // total 24 // -rw-r--r-- 1 jacek wheel 248 7 sie 11:35 0 // -rw-r--r-- 1 jacek wheel 248 7 sie 11:37 1 // -rw-r--r-- 1 jacek wheel 248 7 sie 11:38 2 // $ tail -2 /tmp/checkpoint/offsets/2 | jq</p> <p>// Stop the streaming query q.stop</p> <p>// And start over to see what offset the query starts from // Checkpoint location should have the offsets val q = records. writeStream. format("console"). option("truncate", false). option("checkpointLocation", "/tmp/checkpoint"). // &larr; checkpoint directory trigger(Trigger.ProcessingTime(10.seconds)). outputMode(OutputMode.Update). start // Whoops...console format does not support recovery (!) // Reported as <a href=https://issues.apache.org/jira/browse/SPARK-21667>https://issues.apache.org/jira/browse/SPARK-21667</a> org.apache.spark.sql.AnalysisException: This query does not support recovering from checkpoint location. Delete /tmp/checkpoint/offsets to start over.; at org.apache.spark.sql.streaming.StreamingQueryManager.createQuery(StreamingQueryManager.scala:222) at org.apache.spark.sql.streaming.StreamingQueryManager.startQuery(StreamingQueryManager.scala:278) at org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:284) ... 61 elided</p> <p>// Change the sink (= output format) to JSON val q = records. writeStream. format("json"). option("path", "/tmp/json-sink"). option("checkpointLocation", "/tmp/checkpoint"). // &larr; checkpoint directory trigger(Trigger.ProcessingTime(10.seconds)). start // Note the checkpoint directory in use 17/08/07 12:09:02 INFO StreamExecution: Starting [id = 02e00924-5f0d-4501-bcb8-80be8a8be385, runId = 5eba2576-dad6-4f95-9031-e72514475edc] with file:///tmp/checkpoint to store the query checkpoint. ... 17/08/07 12:09:02 INFO KafkaSource: GetBatch called with start = Some({"topic1":{"0":3}}), end = {"topic1":{"0":4}} 17/08/07 12:09:02 INFO KafkaSource: Partitions added: Map() 17/08/07 12:09:02 DEBUG KafkaSource: TopicPartitions: topic1-0 17/08/07 12:09:02 DEBUG KafkaSource: Sorted executors: 17/08/07 12:09:02 INFO KafkaSource: GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(topic1-0,3,4,None) 17/08/07 12:09:03 DEBUG KafkaOffsetReader: Partitions assigned to consumer: [topic1-0]. Seeking to the end. 17/08/07 12:09:03 DEBUG KafkaOffsetReader: Got latest offsets for partition : Map(topic1-0 -&gt; 4) 17/08/07 12:09:03 DEBUG KafkaSource: GetOffset: ArrayBuffer((topic1-0,4)) 17/08/07 12:09:03 DEBUG StreamExecution: getOffset took 122 ms 17/08/07 12:09:03 DEBUG StreamExecution: Resuming at batch 3 with committed offsets {KafkaSource[Subscribe[topic1]]: {"topic1":{"0":4}}} and available offsets {KafkaSource[Subscribe[topic1]]: {"topic1":{"0":4}}} 17/08/07 12:09:03 DEBUG StreamExecution: Stream running from {KafkaSource[Subscribe[topic1]]: {"topic1":{"0":4}}} to {KafkaSource[Subscribe[topic1]]: {"topic1":{"0":4}}}</p> <hr> <p><code>getOffset</code> requests &lt;<kafkareader, kafkaoffsetreader>&gt; to <a href=../KafkaOffsetReader/#fetchLatestOffsets>fetchLatestOffsets</a> (known later as <code>latest</code>).</p> <p>NOTE: (Possible performance degradation?) It is possible that <code>getOffset</code> will request the latest offsets from Kafka twice, i.e. while initializing &lt;<initialpartitionoffsets, initialpartitionoffsets>&gt; (when no metadata log is available and KafkaSource's &lt;<startingoffsets, kafkaoffsetrangelimit>&gt; is <code>LatestOffsetRangeLimit</code>) and always as part of <code>getOffset</code> itself.</p> <p><code>getOffset</code> then calculates &lt;<currentpartitionoffsets, currentpartitionoffsets>&gt; based on the &lt;<maxoffsetspertrigger, maxoffsetspertrigger>&gt; option.</p> <p>.getOffset's Offset Calculation per maxOffsetsPerTrigger [cols="1,1",options="header",width="100%"] |=== | maxOffsetsPerTrigger | Offsets</p> <p>| Unspecified (i.e. <code>None</code>) | <code>latest</code></p> <p>| Defined (but &lt;<currentpartitionoffsets, currentpartitionoffsets>&gt; is empty) | &lt;<ratelimit, ratelimit>&gt; with <code>limit</code> limit, &lt;<initialpartitionoffsets, initialpartitionoffsets>&gt; as <code>from</code>, <code>until</code> as <code>latest</code></p> <p>| Defined (and &lt;<currentpartitionoffsets, currentpartitionoffsets>&gt; contains partitions and offsets) | &lt;<ratelimit, ratelimit>&gt; with <code>limit</code> limit, &lt;<currentpartitionoffsets, currentpartitionoffsets>&gt; as <code>from</code>, <code>until</code> as <code>latest</code> |===</p> <p>You should see the following DEBUG message in the logs:</p> <div class=highlight><pre><span></span><code>GetOffset: [offsets]
</code></pre></div> <p>In the end, <code>getOffset</code> creates a <a href=../KafkaSourceOffset/ >KafkaSourceOffset</a> with <code>offsets</code> (as <code>Map[TopicPartition, Long]</code>).</p> <p>=== [[fetchAndVerify]] Fetching and Verifying Specific Offsets -- <code>fetchAndVerify</code> Internal Method</p> <h2 id=source-scala_3>[source, scala]<a class=headerlink href=#source-scala_3 title="Permanent link">&para;</a></h2> <h2 id=fetchandverifyspecificoffsets-maptopicpartition-long-kafkasourceoffset>fetchAndVerify(specificOffsets: Map[TopicPartition, Long]): KafkaSourceOffset<a class=headerlink href=#fetchandverifyspecificoffsets-maptopicpartition-long-kafkasourceoffset title="Permanent link">&para;</a></h2> <p><code>fetchAndVerify</code> requests &lt;<kafkareader, kafkaoffsetreader>&gt; to <a href=../KafkaOffsetReader/#fetchSpecificOffsets>fetchSpecificOffsets</a> for the given <code>specificOffsets</code>.</p> <p><code>fetchAndVerify</code> makes sure that the starting offsets in <code>specificOffsets</code> are the same as in Kafka and &lt;<reportdataloss, reports a data loss>&gt; otherwise.</p> <div class=highlight><pre><span></span><code>startingOffsets for [tp] was [off] but consumer reset to [result(tp)]
</code></pre></div> <p>In the end, <code>fetchAndVerify</code> creates a <a href=../KafkaSourceOffset/ >KafkaSourceOffset</a> (with the result of &lt;<kafkareader, kafkaoffsetreader>&gt;).</p> <p>NOTE: <code>fetchAndVerify</code> is used exclusively when <code>KafkaSource</code> initializes &lt;<initialpartitionoffsets, initial partition offsets>&gt;.</p> <p>=== [[initialPartitionOffsets]] Initial Partition Offsets (of 0<sup>th</sup> Batch) -- <code>initialPartitionOffsets</code> Internal Lazy Property</p> <h2 id=source-scala_4>[source, scala]<a class=headerlink href=#source-scala_4 title="Permanent link">&para;</a></h2> <h2 id=initialpartitionoffsets-maptopicpartition-long>initialPartitionOffsets: Map[TopicPartition, Long]<a class=headerlink href=#initialpartitionoffsets-maptopicpartition-long title="Permanent link">&para;</a></h2> <p><code>initialPartitionOffsets</code> is the <em>initial partition offsets</em> for the batch <code>0</code> that were already persisted in the &lt;<metadatapath, streaming metadata log directory>&gt; or persisted on demand.</p> <p>As the very first step, <code>initialPartitionOffsets</code> creates a custom &lt;<spark-sql-streaming-hdfsmetadatalog.md#, hdfsmetadatalog>&gt; (of <a href=../KafkaSourceOffset/ >KafkaSourceOffsets</a> metadata) in the &lt;<metadatapath, streaming metadata log directory>&gt;.</p> <p><code>initialPartitionOffsets</code> requests the <code>HDFSMetadataLog</code> for the &lt;<spark-sql-streaming-hdfsmetadatalog.md#get, metadata>&gt; of the <code>0</code>th batch (as <code>KafkaSourceOffset</code>).</p> <p>If the metadata is available, <code>initialPartitionOffsets</code> requests the metadata for the <a href=../KafkaSourceOffset/#partitionToOffsets>collection of TopicPartitions and their offsets</a>.</p> <p>If the metadata could not be found, <code>initialPartitionOffsets</code> creates a new <code>KafkaSourceOffset</code> per &lt;<startingoffsets, kafkaoffsetrangelimit>&gt;:</p> <ul> <li> <p>For <code>EarliestOffsetRangeLimit</code>, <code>initialPartitionOffsets</code> requests the &lt;<kafkareader, kafkaoffsetreader>&gt; to <a href=../KafkaOffsetReader/#fetchEarliestOffsets>fetchEarliestOffsets</a></p> </li> <li> <p>For <code>LatestOffsetRangeLimit</code>, <code>initialPartitionOffsets</code> requests the &lt;<kafkareader, kafkaoffsetreader>&gt; to <a href=../KafkaOffsetReader/#fetchLatestOffsets>fetchLatestOffsets</a></p> </li> <li> <p>For <code>SpecificOffsetRangeLimit</code>, <code>initialPartitionOffsets</code> requests the &lt;<kafkareader, kafkaoffsetreader>&gt; to <a href=../KafkaOffsetReader/#fetchSpecificOffsets>fetchSpecificOffsets</a> (and report a data loss per the &lt;<failondataloss, failondataloss>&gt; flag)</p> </li> </ul> <p><code>initialPartitionOffsets</code> requests the custom <code>HDFSMetadataLog</code> to &lt;<spark-sql-streaming-hdfsmetadatalog.md#add, add the offsets to the metadata log>&gt; (as the metadata of the <code>0</code>th batch).</p> <p><code>initialPartitionOffsets</code> prints out the following INFO message to the logs:</p> <div class=highlight><pre><span></span><code>Initial offsets: [offsets]
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Note</p> <p><code>initialPartitionOffsets</code> is used when <code>KafkaSource</code> is requested for the following:</p> <ul> <li> <p>&lt;<getoffset, fetch offsets (from metadata log or kafka directly)>&gt;</p> </li> <li> <p>&lt;<getbatch, generate a dataframe with records from kafka for a streaming batch>&gt; (when the start offsets are not defined, i.e. before <code>StreamExecution</code> <a href=../../../StreamExecution/#runStream>commits the first streaming batch</a> and so nothing is in <a href=../../../StreamExecution/#committedOffsets>committedOffsets</a> registry for a <code>KafkaSource</code> data source yet)</p> </li> </ul> </div> <p>==== [[initialPartitionOffsets-HDFSMetadataLog-serialize]] <code>HDFSMetadataLog.serialize</code></p> <h2 id=source-scala_5>[source, scala]<a class=headerlink href=#source-scala_5 title="Permanent link">&para;</a></h2> <p>serialize( metadata: KafkaSourceOffset, out: OutputStream): Unit</p> <hr> <p>NOTE: <code>serialize</code> is part of the &lt;<spark-sql-streaming-hdfsmetadatalog.md#serialize, hdfsmetadatalog contract>&gt; to...FIXME.</p> <p><code>serialize</code> requests the <code>OutputStream</code> to write a zero byte (to support Spark 2.1.0 as per SPARK-19517).</p> <p><code>serialize</code> creates a <code>BufferedWriter</code> over a <code>OutputStreamWriter</code> over the <code>OutputStream</code> (with <code>UTF_8</code> charset encoding).</p> <p><code>serialize</code> requests the <code>BufferedWriter</code> to write the <em>v1</em> version indicator followed by a new line.</p> <p><code>serialize</code> then requests the <code>KafkaSourceOffset</code> for a JSON-serialized representation and the <code>BufferedWriter</code> to write it out.</p> <p>In the end, <code>serialize</code> requests the <code>BufferedWriter</code> to flush (the underlying stream).</p> <p>=== [[rateLimit]] <code>rateLimit</code> Internal Method</p> <h2 id=source-scala_6>[source, scala]<a class=headerlink href=#source-scala_6 title="Permanent link">&para;</a></h2> <p>rateLimit( limit: Long, from: Map[TopicPartition, Long], until: Map[TopicPartition, Long]): Map[TopicPartition, Long]</p> <hr> <p><code>rateLimit</code> requests &lt;<kafkareader, kafkaoffsetreader>&gt; to <a href=../KafkaOffsetReader/#fetchEarliestOffsets>fetchEarliestOffsets</a>.</p> <p>CAUTION: FIXME</p> <p>NOTE: <code>rateLimit</code> is used exclusively when <code>KafkaSource</code> &lt;<getoffset, gets available offsets>&gt; (when &lt;<maxoffsetspertrigger, maxoffsetspertrigger>&gt; option is specified).</p> <p>=== [[getSortedExecutorList]] <code>getSortedExecutorList</code> Method</p> <p>CAUTION: FIXME</p> <p>=== [[reportDataLoss]] <code>reportDataLoss</code> Internal Method</p> <p>CAUTION: FIXME</p> <h1 id=note>[NOTE]<a class=headerlink href=#note title="Permanent link">&para;</a></h1> <p><code>reportDataLoss</code> is used when <code>KafkaSource</code> does the following:</p> <ul> <li>&lt;<fetchandverify, fetches and verifies specific offsets>&gt;</li> <li> <h1 id=_1>&lt;<getbatch, generates a dataframe with records from kafka for a batch>&gt;<a class=headerlink href=#_1 title="Permanent link">&para;</a></h1> </li> </ul> <p>=== [[internal-properties]] Internal Properties</p> <p>[cols="30m,70",options="header",width="100%"] |=== | Name | Description</p> <p>| currentPartitionOffsets | [[currentPartitionOffsets]] Current partition offsets (as <code>Map[TopicPartition, Long]</code>)</p> <p>Initially <code>NONE</code> and set when <code>KafkaSource</code> is requested to &lt;<getoffset, get the maximum available offsets>&gt; or &lt;<getbatch, generate a dataframe with records from kafka for a batch>&gt;.</p> <p>| pollTimeoutMs a| [[pollTimeoutMs]]</p> <p>| sc a| [[sc]] Spark Core's <code>SparkContext</code> (of the &lt;<sqlcontext, sqlcontext>&gt;)</p> <p>Used when:</p> <ul> <li> <p>&lt;<getbatch, generating a dataframe with records from kafka for a streaming micro-batch>&gt; (and creating a <a href=../KafkaSourceRDD/ >KafkaSourceRDD</a>)</p> </li> <li> <p>Initializing the <a href=#pollTimeoutMs>pollTimeoutMs</a> internal property</p> </li> </ul> <p>|===</p> </article> </div> </div> </main> <footer class=md-footer> <div class=md-footer-nav> <nav class="md-footer-nav__inner md-grid" aria-label=Footer> <a href=../KafkaTable/ class="md-footer-nav__link md-footer-nav__link--prev" rel=prev> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Previous </span> KafkaTable </div> </div> </a> <a href=../KafkaRelation/ class="md-footer-nav__link md-footer-nav__link--next" rel=next> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Next </span> KafkaRelation </div> </div> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2020 <a href=https://twitter.com/jaceklaskowski target=_blank rel=noopener>Jacek Laskowski</a> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-footer-social> <a href=https://github.com/jaceklaskowski target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://twitter.com/jaceklaskowski target=_blank rel=noopener title=twitter.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> <a href=https://linkedin.com/in/jaceklaskowski target=_blank rel=noopener title=linkedin.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> </div> </div> </div> </footer> </div> <script src=../../../assets/javascripts/vendor.77e55a48.min.js></script> <script src=../../../assets/javascripts/bundle.9554a270.min.js></script><script id=__lang type=application/json>{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script> <script>
        app = initialize({
          base: "../../..",
          features: ['navigation.tabs', 'navigation.instant'],
          search: Object.assign({
            worker: "../../../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script> </body> </html>