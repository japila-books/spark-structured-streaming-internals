== [[OutputMode]] OutputMode

*Output mode* (`OutputMode`) describes what data is written to a link:spark-sql-streaming-Sink.adoc[streaming sink] when there is new data available in link:spark-sql-streaming-Source.adoc[streaming data sources] (in a trigger / streaming batch).

Output mode of a streaming query is specified using link:spark-sql-streaming-DataStreamWriter.adoc#outputMode[outputMode] method of `DataStreamWriter`.

[source, scala]
----
val inputStream = spark.
  readStream.
  format("rate").
  load
import org.apache.spark.sql.streaming.{OutputMode, Trigger}
import scala.concurrent.duration._
val consoleOutput = inputStream.
  writeStream.
  format("console").
  option("truncate", false).
  trigger(Trigger.ProcessingTime(10.seconds)).
  queryName("rate-console").
  option("checkpointLocation", "checkpoint").
  outputMode(OutputMode.Update).  // <-- update output mode
  start
----

[[available-output-modes]]
.Available Output Modes
[cols="1,1,2",options="header",width="100%"]
|===
| OutputMode
| Name
| Behaviour

| [[Append]] `Append`
| `append`
a|

[[default-output-mode]]
link:spark-sql-streaming-DataStreamWriter.adoc#outputMode[Default output mode] that writes "new" rows only.

NOTE: For streaming aggregations, "new" row is when the intermediate state is made final, i.e. when new events for the grouping key can only be considered late which is when watermark moves past the event time of the key.

NOTE: `Append` output mode requires that a streaming query defines event time watermark (using link:spark-sql-streaming-Dataset-withWatermark.adoc[withWatermark] operator) on the event time column that is used in aggregation (directly or using link:spark-sql-streaming-window.adoc[window] function).

Required for datasets with `FileFormat` format (to create link:spark-sql-streaming-FileStreamSink.adoc[FileStreamSink])

Used for link:spark-sql-streaming-KeyValueGroupedDataset.adoc#flatMapGroupsWithState[flatMapGroupsWithState] operator

| [[Complete]] `Complete`
| `complete`
a| Writes all rows (every time there are updates) and therefore corresponds to a traditional batch query.

NOTE: Supported only for streaming queries with link:spark-sql-streaming-Dataset-operators.adoc#groupBy[groupBy] or link:spark-sql-streaming-Dataset-operators.adoc#groupByKey[groupByKey] aggregations (as asserted by link:spark-sql-streaming-UnsupportedOperationChecker.adoc#checkForStreaming[UnsupportedOperationChecker]).

| [[Update]] `Update`
| `update`
| Write the rows that were updated (every time there are updates). If the query does not contain aggregations, it is equivalent to <<Append, Append>> mode.

Used for link:spark-sql-streaming-KeyValueGroupedDataset.adoc#mapGroupsWithState[mapGroupsWithState] and link:spark-sql-streaming-KeyValueGroupedDataset.adoc#flatMapGroupsWithState[flatMapGroupsWithState] operators
|===
